{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>manntal</th>\n",
       "      <th>nafn</th>\n",
       "      <th>faedingarar</th>\n",
       "      <th>kyn</th>\n",
       "      <th>stada</th>\n",
       "      <th>hjuskapur</th>\n",
       "      <th>bi_einstaklingur</th>\n",
       "      <th>bi_baer</th>\n",
       "      <th>bi_hreppur</th>\n",
       "      <th>bi_sokn</th>\n",
       "      <th>bi_sysla</th>\n",
       "      <th>cleaned_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>491129</th>\n",
       "      <td>780730</td>\n",
       "      <td>1801</td>\n",
       "      <td>Una Helge d</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>Kona</td>\n",
       "      <td>deres datter</td>\n",
       "      <td>Ó</td>\n",
       "      <td>345456.0</td>\n",
       "      <td>9659.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>12</td>\n",
       "      <td>deres datter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491130</th>\n",
       "      <td>38269</td>\n",
       "      <td>1835</td>\n",
       "      <td>Ingibjörg Símonardóttir</td>\n",
       "      <td>1832.0</td>\n",
       "      <td>Kona</td>\n",
       "      <td>þeirra barn</td>\n",
       "      <td>Ó</td>\n",
       "      <td>345457.0</td>\n",
       "      <td>4453.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Barn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491131</th>\n",
       "      <td>101212</td>\n",
       "      <td>1840</td>\n",
       "      <td>Ingibjörg Símonardóttir</td>\n",
       "      <td>1832.0</td>\n",
       "      <td>Kona</td>\n",
       "      <td>hans barn</td>\n",
       "      <td>Ó</td>\n",
       "      <td>345457.0</td>\n",
       "      <td>4442.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Barn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491132</th>\n",
       "      <td>4592</td>\n",
       "      <td>1835</td>\n",
       "      <td>Helga Símonardóttir</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>Kona</td>\n",
       "      <td>þeirra barn</td>\n",
       "      <td>Ó</td>\n",
       "      <td>345458.0</td>\n",
       "      <td>4453.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Barn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491133</th>\n",
       "      <td>101210</td>\n",
       "      <td>1840</td>\n",
       "      <td>Helga Símonardóttir</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>Kona</td>\n",
       "      <td>hans barn</td>\n",
       "      <td>Ó</td>\n",
       "      <td>345458.0</td>\n",
       "      <td>4442.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Barn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  manntal                     nafn  faedingarar   kyn  \\\n",
       "491129  780730     1801              Una Helge d       1800.0  Kona   \n",
       "491130   38269     1835  Ingibjörg Símonardóttir       1832.0  Kona   \n",
       "491131  101212     1840  Ingibjörg Símonardóttir       1832.0  Kona   \n",
       "491132    4592     1835      Helga Símonardóttir       1831.0  Kona   \n",
       "491133  101210     1840      Helga Símonardóttir       1831.0  Kona   \n",
       "\n",
       "               stada hjuskapur  bi_einstaklingur  bi_baer  bi_hreppur  \\\n",
       "491129  deres datter         Ó          345456.0   9659.0       278.0   \n",
       "491130   þeirra barn         Ó          345457.0   4453.0       278.0   \n",
       "491131     hans barn         Ó          345457.0   4442.0       275.0   \n",
       "491132   þeirra barn         Ó          345458.0   4453.0       278.0   \n",
       "491133     hans barn         Ó          345458.0   4442.0       275.0   \n",
       "\n",
       "        bi_sokn  bi_sysla cleaned_status  \n",
       "491129    332.0        12   deres datter  \n",
       "491130    334.0        12           Barn  \n",
       "491131    331.0        12           Barn  \n",
       "491132    334.0        12           Barn  \n",
       "491133    331.0        12           Barn  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sander_final/rule_based_predictions.csv')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop([\"fornafn\", \"millinafn\", \"eftirnafn\", \"aettarnafn\", \"uniqueness_score\", \"score\", \"id_individual\"], axis=1, inplace=True)\n",
    "df.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491134\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_path = \"intermediate_data/\"\n",
    "\n",
    "word2vec_model_path = os.path.join(intermediate_path, 'word2vec_model')\n",
    "encoded_df_path = os.path.join(intermediate_path, 'encoded_df.pkl')\n",
    "pairs_df_path = os.path.join(intermediate_path, 'pairs_df.pkl')\n",
    "balanced_df_path = os.path.join(intermediate_path, 'balanced_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('intermediate_data/encoded_df.pkl')\n",
    "X_train = np.load('intermediate_data/X_train.npy', allow_pickle=True)\n",
    "X_train_df = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Pipeline\n",
    "\n",
    "## Step 1: Cleaning and Exclusion of Single-member Clusters\n",
    "\n",
    "- **Total Single-member Clusters Excluded:** 120,112\n",
    "- The cleaned dataset is saved after excluding these clusters.\n",
    "\n",
    "## Step 2: Handling Missing and Redundant Columns\n",
    "\n",
    "- **Dropped Columns:** Some columns like `fornafn`, `millinafn`, `eftirnafn`, `aettarnafn`, and `stada` were dropped due to redundancy or irrelevance for the model.\n",
    "- The cleaned `nafn` column is kept for further processing.\n",
    "\n",
    "## Step 3: Word2Vec Embedding for Names\n",
    "\n",
    "A Word2Vec model was trained on Icelandic names from the dataset to generate meaningful name embeddings. This step helps convert text data into numerical vectors that can be used by machine learning models.\n",
    "- **Word2Vec Model Hyperparameters:**\n",
    "  - Vector size: 100\n",
    "  - Window: 5\n",
    "  - Minimum count: 1\n",
    "  - Workers: 4\n",
    "- The `nafn` column is embedded, and the resulting 100-dimensional vector is split into individual columns.\n",
    "\n",
    "## Step 4: Categorical Encoding\n",
    "\n",
    "Categorical features were either one-hot encoded or label encoded, depending on their cardinality:\n",
    "- **Categorical Features:**\n",
    "  - `kyn`, `hjuskapur`, `cleaned_status`, `bi_baer`, `manntal`, `bi_hreppur`, `bi_sokn`, `bi_sysla`\n",
    "- Features with fewer than 50 unique values were one-hot encoded, while those with higher cardinality were label-encoded.\n",
    "\n",
    "| Categorical Feature  | Encoding Method       |\n",
    "|----------------------|-----------------------|\n",
    "| kyn                  | One-hot encoding      |\n",
    "| hjuskapur            | One-hot encoding      |\n",
    "| cleaned_status       | One-hot encoding      |\n",
    "| bi_baer              | Label encoding        |\n",
    "| manntal              | Label encoding        |\n",
    "| bi_hreppur           | Label encoding        |\n",
    "| bi_sokn              | Label encoding        |\n",
    "| bi_sysla             | Label encoding        |\n",
    "\n",
    "## Step 5: Numerical Feature Scaling\n",
    "\n",
    "Numerical features were standardized to ensure consistent scaling across features.\n",
    "- **Numerical Features:**\n",
    "  - `faedingarar`\n",
    "- **Scaling Method:** StandardScaler was used to scale these features to have mean 0 and standard deviation 1.\n",
    "\n",
    "## Step 6: PCA for Dimensionality Reduction\n",
    "\n",
    "Principal Component Analysis (PCA) was applied to reduce the dimensionality of the dataset while retaining 95% of the variance.\n",
    "- **PCA Components:** The number of components is automatically determined to retain 95% of the variance.\n",
    "- PCA-transformed data was saved for both the training and test sets.\n",
    "\n",
    "## Step 7: Data Splitting\n",
    "\n",
    "After PCA transformation, the dataset was split into training and test sets. \n",
    "- **Test Size:** 20% of the dataset was set aside for testing.\n",
    "- **Random State:** 42\n",
    "\n",
    "## Summary of Saved Files:\n",
    "- Excluded single-member clusters: `excluded_single_member_clusters.csv`\n",
    "- Processed data after encoding: `encoded_df.pkl`\n",
    "- OneHotEncoder model: `encoder.pkl`\n",
    "- StandardScaler model: `scaler.pkl`\n",
    "- LabelEncoders for high cardinality features: `label_encoders.pkl`\n",
    "- PCA-transformed training data: `train_pca_data.pkl`\n",
    "- PCA-transformed test data: `test_pca_data.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding names using Word2Vec...\n",
      "Processing full dataset before excluding single-member clusters...\n",
      "Initializing encoders and scalers...\n",
      "Encoding categorical features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea826fdd738408da35cd4134ea796b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Categorical Features:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features encoded. Shape: (491134, 66)\n",
      "Scaling numerical features...\n",
      "Numerical features scaled. Shape: (491134, 1)\n",
      "Combining all features into a single DataFrame...\n",
      "Checking for NaN values in processed DataFrame...\n",
      "Processed dataframe saved to temp_data/encoded_df.pkl\n",
      "OneHotEncoder saved to temp_data/encoder.pkl\n",
      "StandardScaler saved to temp_data/scaler.pkl\n",
      "LabelEncoders saved to temp_data/label_encoders.pkl\n",
      "Excluded 120112 single-member clusters. Saved to 'excluded_single_member_clusters.csv'.\n",
      "Whole preprocessed dataset saved to temp_data/preprocessed_full_data_without_pairs.pkl\n",
      "Applying PCA to the processed dataset...\n",
      "PCA-transformed dataset saved to temp_data/pca_transformed_data.pkl\n",
      "Splitting PCA-transformed dataset into training and test sets...\n",
      "PCA applied, data saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "from jellyfish import levenshtein_distance, jaro_winkler_similarity\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('sander_final/rule_based_predictions.csv')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns, but KEEP 'bi_einstaklingur' for further processing\n",
    "df.drop(columns=[\"fornafn\", \"millinafn\", \"eftirnafn\", \"aettarnafn\", \"stada\", \"id_individual\"], inplace=True)\n",
    "\n",
    "# Define paths for intermediate files\n",
    "temp_path = 'temp_data/'\n",
    "os.makedirs(temp_path, exist_ok=True)\n",
    "\n",
    "word2vec_model_path = os.path.join(temp_path, 'word2vec_model')\n",
    "encoded_df_path = os.path.join(temp_path, 'encoded_df.pkl')\n",
    "encoder_path = os.path.join(temp_path, 'encoder.pkl')\n",
    "scaler_path = os.path.join(temp_path, 'scaler.pkl')\n",
    "label_encoders_path = os.path.join(temp_path, 'label_encoders.pkl')\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = [\n",
    "    'kyn', 'hjuskapur', 'cleaned_status',\n",
    "    'bi_baer', 'manntal', 'bi_hreppur', 'bi_sokn', 'bi_sysla'\n",
    "]\n",
    "numerical_features = ['faedingarar']\n",
    "\n",
    "# Threshold for switching from one-hot to label encoding\n",
    "high_cardinality_threshold = 50\n",
    "\n",
    "# Clean the name by removing numbers and special characters\n",
    "def clean_name(name):\n",
    "    return re.sub(r'[^a-zA-ZáéíóúýðæöþÁÉÍÓÚÝÐÆÖÞ ]', '', name)\n",
    "\n",
    "# Train Word2Vec model on Icelandic names and overwrite existing models\n",
    "def train_word2vec(df, word2vec_model_path):\n",
    "    df['cleaned_nafn'] = df['nafn'].apply(clean_name)\n",
    "    names_list = df['cleaned_nafn'].apply(lambda x: x.split()).tolist()\n",
    "    word2vec_model = Word2Vec(sentences=names_list, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    word2vec_model.save(word2vec_model_path)\n",
    "    return word2vec_model\n",
    "\n",
    "word2vec_model = train_word2vec(df, word2vec_model_path)\n",
    "\n",
    "# Function to get Word2Vec name embeddings\n",
    "def get_name_embedding(name, model):\n",
    "    words = clean_name(name).split()\n",
    "    embeddings = [model.wv[word] for word in words if word in model.wv]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Ensure 'nafn' column is properly embedded using Word2Vec\n",
    "def embed_names(df, word2vec_model):\n",
    "    print(\"Embedding names using Word2Vec...\")\n",
    "    df['name_embedding'] = df['nafn'].apply(lambda name: get_name_embedding(name, word2vec_model))\n",
    "    \n",
    "    # Drop 'nafn' column since we now have its embedding\n",
    "    df.drop(columns=['nafn'], inplace=True)\n",
    "    \n",
    "    # Split embedding into separate columns for each dimension (assuming embedding size is 100)\n",
    "    embedding_dim = word2vec_model.vector_size\n",
    "    name_embedding_df = pd.DataFrame(df['name_embedding'].to_list(), columns=[f'name_emb_{i}' for i in range(embedding_dim)])\n",
    "    \n",
    "    # Concatenate the new embedding columns with the main dataframe\n",
    "    df = pd.concat([df, name_embedding_df], axis=1)\n",
    "    \n",
    "    # Drop the original 'name_embedding' column now that it's split\n",
    "    df.drop(columns=['name_embedding'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the embedding before splitting and processing\n",
    "df = embed_names(df, word2vec_model)\n",
    "\n",
    "# Process and encode the DataFrame\n",
    "def process_dataframe(df):\n",
    "    print(\"Initializing encoders and scalers...\")\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    label_encoders = {}\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Prepare DataFrame for encoded features\n",
    "    encoded_df = pd.DataFrame()\n",
    "\n",
    "    all_feature_names = []  # Track all feature names\n",
    "\n",
    "    # Encode categorical features\n",
    "    print(\"Encoding categorical features...\")\n",
    "    for feature in tqdm(categorical_features, desc=\"Encoding Categorical Features\"):\n",
    "        n_unique = df[feature].nunique()\n",
    "        if n_unique <= high_cardinality_threshold:\n",
    "            # One-hot encode features with low cardinality\n",
    "            encoded_feature = encoder.fit_transform(df[[feature]])\n",
    "            feature_names = encoder.get_feature_names_out([feature])\n",
    "            all_feature_names.extend(feature_names)\n",
    "            encoded_df = pd.concat([encoded_df, pd.DataFrame(encoded_feature, columns=feature_names)], axis=1)\n",
    "        else:\n",
    "            # Label encode features with high cardinality\n",
    "            label_encoders[feature] = LabelEncoder()\n",
    "            df.loc[:, feature] = label_encoders[feature].fit_transform(df[feature])\n",
    "            all_feature_names.append(feature)\n",
    "            encoded_df[feature] = df[feature]\n",
    "\n",
    "    print(f\"Categorical features encoded. Shape: {encoded_df.shape}\")\n",
    "\n",
    "    # Scale numerical features\n",
    "    print(\"Scaling numerical features...\")\n",
    "    df[numerical_features] = df[numerical_features].fillna(0).astype('float32')\n",
    "    scaled_num = scaler.fit_transform(df[numerical_features])\n",
    "    scaled_num_df = pd.DataFrame(scaled_num, columns=numerical_features)\n",
    "    all_feature_names.extend(numerical_features)\n",
    "    print(f\"Numerical features scaled. Shape: {scaled_num.shape}\")\n",
    "\n",
    "    # Combine all features into a single DataFrame\n",
    "    print(\"Combining all features into a single DataFrame...\")\n",
    "    processed_df = pd.concat([df[['id', 'bi_einstaklingur']], encoded_df, scaled_num_df], axis=1)  # Include bi_einstaklingur\n",
    "    \n",
    "    # Debugging: Check for NaN values after processing\n",
    "    print(f\"Checking for NaN values in processed DataFrame...\")\n",
    "    processed_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Save the processed DataFrame to a file\n",
    "    processed_df.to_pickle(encoded_df_path)\n",
    "    print(f\"Processed dataframe saved to {encoded_df_path}\")\n",
    "\n",
    "    # Save encoders and scalers (overwrite existing ones)\n",
    "    with open(encoder_path, 'wb') as f:\n",
    "        pickle.dump(encoder, f)\n",
    "    print(f\"OneHotEncoder saved to {encoder_path}\")\n",
    "\n",
    "    with open(scaler_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    print(f\"StandardScaler saved to {scaler_path}\")\n",
    "\n",
    "    with open(label_encoders_path, 'wb') as f:\n",
    "        pickle.dump(label_encoders, f)\n",
    "    print(f\"LabelEncoders saved to {label_encoders_path}\")\n",
    "\n",
    "    return processed_df, all_feature_names\n",
    "\n",
    "# Main Execution\n",
    "print(\"Processing full dataset before excluding single-member clusters...\")\n",
    "processed_full_df, all_feature_names = process_dataframe(df)\n",
    "\n",
    "# Step 1: Count the number of occurrences of each bi_einstaklingur\n",
    "bi_einstaklingur_df = processed_full_df[['id', 'bi_einstaklingur']].copy()\n",
    "cluster_counts = bi_einstaklingur_df['bi_einstaklingur'].value_counts()\n",
    "\n",
    "# Step 2: Identify clusters with only one member (single-member clusters)\n",
    "single_member_clusters = cluster_counts[cluster_counts == 1].index\n",
    "\n",
    "# Step 3: Exclude rows where bi_einstaklingur has only one member\n",
    "excluded_df = processed_full_df.loc[processed_full_df['bi_einstaklingur'].isin(single_member_clusters)]\n",
    "processed_full_df = processed_full_df.loc[~processed_full_df['bi_einstaklingur'].isin(single_member_clusters)]\n",
    "\n",
    "# Step 4: Save excluded single-member clusters to CSV\n",
    "excluded_df.to_csv('excluded_single_member_clusters.csv', index=False)\n",
    "print(f\"Excluded {len(excluded_df)} single-member clusters. Saved to 'excluded_single_member_clusters.csv'.\")\n",
    "\n",
    "# Save the whole preprocessed dataset without formulating pairs\n",
    "preprocessed_data_path = os.path.join(temp_path, 'preprocessed_full_data_without_pairs.pkl')\n",
    "\n",
    "# Saving the processed dataset before forming pairs\n",
    "processed_full_df.to_pickle(preprocessed_data_path)\n",
    "\n",
    "print(f\"Whole preprocessed dataset saved to {preprocessed_data_path}\")\n",
    "\n",
    "# Apply PCA while retaining 95% of variance\n",
    "print(\"Applying PCA to the processed dataset...\")\n",
    "pca = PCA(n_components=0.95)\n",
    "pca_transformed = pca.fit_transform(processed_full_df.drop(columns=['id', 'bi_einstaklingur']))\n",
    "\n",
    "# Re-attach 'id' and 'bi_einstaklingur'\n",
    "full_pca_df = pd.DataFrame(pca_transformed, columns=[f'pca_{i}' for i in range(pca_transformed.shape[1])])\n",
    "full_pca_df['id'] = processed_full_df['id'].values\n",
    "full_pca_df['bi_einstaklingur'] = processed_full_df['bi_einstaklingur'].values\n",
    "\n",
    "# Save the PCA-transformed dataset with 'id' and 'bi_einstaklingur'\n",
    "full_pca_data_path = os.path.join(temp_path, 'pca_transformed_data.pkl')\n",
    "full_pca_df.to_pickle(full_pca_data_path)\n",
    "print(f\"PCA-transformed dataset saved to {full_pca_data_path}\")\n",
    "\n",
    "# Split the PCA-transformed dataset into training and testing sets\n",
    "def split_data_after_pca(full_pca_df, bi_einstaklingur_df, test_size=0.2, random_state=42):\n",
    "    unique_clusters = bi_einstaklingur_df['bi_einstaklingur'].unique()\n",
    "    train_clusters, test_clusters = train_test_split(unique_clusters, test_size=test_size, random_state=random_state)\n",
    "    train_df = full_pca_df[full_pca_df['id'].isin(bi_einstaklingur_df[bi_einstaklingur_df['bi_einstaklingur'].isin(train_clusters)]['id'])]\n",
    "    test_df = full_pca_df[full_pca_df['id'].isin(bi_einstaklingur_df[bi_einstaklingur_df['bi_einstaklingur'].isin(test_clusters)]['id'])]\n",
    "    return train_df, test_df\n",
    "\n",
    "print(\"Splitting PCA-transformed dataset into training and test sets...\")\n",
    "train_pca_df, test_pca_df = split_data_after_pca(full_pca_df, bi_einstaklingur_df)\n",
    "\n",
    "# Save PCA model and processed data (overwrite existing)\n",
    "with open(os.path.join(temp_path, 'pca_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(pca, f)\n",
    "\n",
    "train_pca_df.to_pickle(os.path.join(temp_path, 'train_pca_data.pkl'))\n",
    "test_pca_df.to_pickle(os.path.join(temp_path, 'test_pca_data.pkl'))\n",
    "\n",
    "print(\"PCA applied, data saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where id == bi_einstaklingur: 14\n",
      "           id  manntal  faedingarar   kyn hjuskapur  bi_einstaklingur  \\\n",
      "5778   1787.0   1835.0       1827.0  Kona         Ó            1787.0   \n",
      "8152   2553.0   1835.0       1828.0  Kona         Ó            2553.0   \n",
      "9215   2900.0   1835.0       1795.0  Kona         Ó            2900.0   \n",
      "9660   3022.0   1835.0       1804.0  Karl         Ó            3022.0   \n",
      "13212  4108.0   1835.0       1834.0  Karl         Ó            4108.0   \n",
      "\n",
      "       bi_baer  bi_hreppur  bi_sokn  bi_sysla  ... name_emb_90  name_emb_91  \\\n",
      "5778    3778.0       160.0    221.0       8.0  ...    0.508287     0.142374   \n",
      "8152    2452.0       100.0    142.0      37.0  ...    0.530053     0.109314   \n",
      "9215    4325.0       193.0    263.0      12.0  ...    0.346079     0.382404   \n",
      "9660    4431.0       199.0    270.0      12.0  ...    0.362282    -0.020432   \n",
      "13212   5044.0       236.0    325.0      14.0  ...    0.313303    -0.053527   \n",
      "\n",
      "       name_emb_92 name_emb_93  name_emb_94  name_emb_95  name_emb_96  \\\n",
      "5778     -0.106300    0.683127     0.912287     0.228690    -0.855477   \n",
      "8152     -0.129282    0.720145     0.908783     0.277519    -0.980168   \n",
      "9215      0.402747   -0.521878    -0.042740     0.208808    -0.508049   \n",
      "9660      0.055977    0.335723     0.472563     0.220658    -0.524804   \n",
      "13212     0.844686   -0.742700     0.007757     0.445798     0.662733   \n",
      "\n",
      "       name_emb_97  name_emb_98  name_emb_99  \n",
      "5778     -0.477782     0.317524    -0.016770  \n",
      "8152     -0.509197     0.313813    -0.015268  \n",
      "9215     -0.852818    -0.255663     0.256333  \n",
      "9660     -0.407075     0.145869     0.054584  \n",
      "13212    -0.432319    -0.045696     0.590149  \n",
      "\n",
      "[5 rows x 114 columns]\n",
      "Number of single-member clusters where id == bi_einstaklingur: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any rows where id == bi_einstaklingur\n",
    "single_instance_rows = df[df['id'] == df['bi_einstaklingur']]\n",
    "\n",
    "# Print the number of such rows\n",
    "print(f\"Number of rows where id == bi_einstaklingur: {len(single_instance_rows)}\")\n",
    "\n",
    "# Optionally, inspect the rows\n",
    "print(single_instance_rows.head())\n",
    "\n",
    "# Check if all single-member classes (those with only one instance) are also rows where id == bi_einstaklingur\n",
    "single_member_clusters_df = df[df['bi_einstaklingur'].isin(single_member_clusters)]\n",
    "rows_with_self_reference = single_member_clusters_df[single_member_clusters_df['id'] == single_member_clusters_df['bi_einstaklingur']]\n",
    "\n",
    "# Print the count of such rows\n",
    "print(f\"Number of single-member clusters where id == bi_einstaklingur: {len(rows_with_self_reference)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **Loading Data**\n",
    "\n",
    "The PCA-transformed training and test datasets were loaded along with the original `bi_einstaklingur` column to help guide the splitting and subsampling for pair generation.\n",
    "\n",
    "- **Train Set Size:** 70% of the full dataset\n",
    "- **Test Set Size:** 30% of the full dataset\n",
    "- **Subsampled Data for Pair Generation:** 50% of each train and test set was used for model training.\n",
    "\n",
    "## 2. **Data Splitting**\n",
    "\n",
    "Data was split based on clusters (`bi_einstaklingur`). Unique clusters were split into the training and test sets, ensuring that each set received its designated portion (70% train, 30% test).\n",
    "\n",
    "- **Train Set Clusters:** Contain clusters of individuals used to generate positive and negative pairs.\n",
    "- **Test Set Clusters:** Clusters reserved for validation and testing.\n",
    "\n",
    "## 3. **Pair Creation**\n",
    "\n",
    "### Positive Pairs\n",
    "Positive pairs are created from rows within the same cluster (`bi_einstaklingur`). For each cluster that contains more than one row, a distinct pair of rows is selected randomly.\n",
    "\n",
    "### Negative Pairs\n",
    "Negative pairs are created by sampling rows from two different clusters. The number of negative pairs is equal to the number of positive pairs to ensure a balanced dataset.\n",
    "\n",
    "| Pair Type         | Train Set (Count) | Test Set (Count) |\n",
    "|-------------------|-------------------|------------------|\n",
    "| **Positive Pairs** | 37,366            | 16,187           |\n",
    "| **Negative Pairs** | 37,366            | 16,187           |\n",
    "| **Total Pairs**    | 74,732            | 32,374           |\n",
    "\n",
    "## 4. **Data Distribution Analysis**\n",
    "\n",
    "We analyzed the distribution of clusters in the generated pairs. Both the training and test sets showed the following distribution:\n",
    "\n",
    "### Cluster Distribution in Train Set\n",
    "- **Positive Pairs:** The number of clusters contributing to positive pairs was checked.\n",
    "- **Negative Pairs:** The number of clusters contributing to negative pairs was also checked.\n",
    "- **Visualization:** The cluster distribution was plotted for both positive and negative pairs.\n",
    "\n",
    "### Cluster Distribution in Test Set\n",
    "- Similar distribution analysis was conducted for the test set.\n",
    "\n",
    "## 5. **Sanity Checks**\n",
    "\n",
    "Sanity checks were performed to ensure the integrity of the dataset:\n",
    "\n",
    "- **Positive vs Negative Pair Counts:** \n",
    "  - The number of positive and negative pairs in both the training and test sets is equal, indicating a balanced dataset.\n",
    "  \n",
    "- **Cluster Representation:**\n",
    "  - Clusters were equally represented in both positive and negative pairs in the train and test sets.\n",
    "\n",
    "| Check                                      | Train Set     | Test Set      |\n",
    "|--------------------------------------------|---------------|---------------|\n",
    "| **Positive vs Negative Pair Balance**      | Passed        | Passed        |\n",
    "| **Equal Cluster Representation in Pairs**  | Passed        | Passed        |\n",
    "\n",
    "## 6. **Saving the Data**\n",
    "\n",
    "The following datasets were saved for further use:\n",
    "- **Full Train and Test Sets:** All positive and negative pairs were saved as separate files.\n",
    "- **Subset Train and Test Sets:** Positive and negative pairs were also saved in separate files for specific analyses.\n",
    "\n",
    "| Dataset                  | File Name                         | Number of Pairs |\n",
    "|--------------------------|-----------------------------------|-----------------|\n",
    "| **Full Train Set**        | `train_full.pkl`                  | 74,732          |\n",
    "| **Full Test Set**         | `test_full.pkl`                   | 32,374          |\n",
    "| **Positive Train Pairs**  | `train_positive_full.pkl`         | 37,366          |\n",
    "| **Negative Train Pairs**  | `train_negative_full.pkl`         | 37,366          |\n",
    "| **Positive Test Pairs**   | `test_positive_full.pkl`          | 16,187          |\n",
    "| **Negative Test Pairs**   | `test_negative_full.pkl`          | 16,187          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PCA-transformed data...\n",
      "Loading original bi_einstaklingur_df for cluster information...\n",
      "Splitting data into training and testing sets based on clusters...\n",
      "Subsampling data to 50.0%...\n",
      "Subsampling data to 50.0%...\n",
      "Creating distinct positive pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ce232ceef64e0d85f090148b55b2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Positive Pairs:   0%|          | 0/63018 [00:00<?, ?cluster/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating negative pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1991cdb211ed4a5896d726681a1cd5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Negative Pairs:   0%|          | 0/37366 [00:00<?, ?pair/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating distinct positive pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e033ba17ad43b1bee2accced20f71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Positive Pairs:   0%|          | 0/27105 [00:00<?, ?cluster/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating negative pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628f5624c4474f09a8e1db758b05a8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Negative Pairs:   0%|          | 0/16187 [00:00<?, ?pair/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Train Set data...\n",
      "Total pairs: 74732\n",
      "Positive pairs: 37366\n",
      "Negative pairs: 37366\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Test Set data...\n",
      "Total pairs: 32374\n",
      "Positive pairs: 16187\n",
      "Negative pairs: 16187\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7eb6d559014c879bda00f1e01013b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving train Data:   0%|          | 0/74732 [00:00<?, ?pair/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full train dataset with 74732 pairs.\n",
      "Saving test dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aece0905c1a94db2b654de1ff19feba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving test Data:   0%|          | 0/32374 [00:00<?, ?pair/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full test dataset with 32374 pairs.\n",
      "Saving train_positive dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61e2332073d4f648dbc6d69aa57a9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving train_positive Data:   0%|          | 0/37366 [00:00<?, ?pair/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full train_positive dataset with 37366 pairs.\n",
      "Saving train_negative dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0c079bd2704b85ace6377a61129cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving train_negative Data:   0%|          | 0/37366 [00:00<?, ?pair/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full train_negative dataset with 37366 pairs.\n",
      "Saving test_positive dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe2361337044e1c921b75fe03fe38eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving test_positive Data:   0%|          | 0/16187 [00:00<?, ?pair/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full test_positive dataset with 16187 pairs.\n",
      "Saving test_negative dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798cb4f223e24d7b89347c7c859a102e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving test_negative Data:   0%|          | 0/16187 [00:00<?, ?pair/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full test_negative dataset with 16187 pairs.\n",
      "Sanity checks for Train Set...\n",
      "Sanity Check Passed: Equal number of positive and negative pairs in Train Set.\n",
      "Sanity Check Failed: Cluster distribution mismatch between positive and negative pairs.\n",
      "Sanity checks for Test Set...\n",
      "Sanity Check Passed: Equal number of positive and negative pairs in Test Set.\n",
      "Sanity Check Failed: Cluster distribution mismatch between positive and negative pairs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm  # For loading bars\n",
    "\n",
    "# Enable tqdm for pandas operations\n",
    "tqdm.pandas()\n",
    "\n",
    "# -------------------- Load Data --------------------\n",
    "print(\"Loading PCA-transformed data...\")\n",
    "train_pca_df = pd.read_pickle(os.path.join('temp_data', 'train_pca_data.pkl'))\n",
    "test_pca_df = pd.read_pickle(os.path.join('temp_data', 'test_pca_data.pkl'))\n",
    "\n",
    "print(\"Loading original bi_einstaklingur_df for cluster information...\")\n",
    "bi_einstaklingur_df = pd.read_csv('sander_final/rule_based_predictions.csv')[['id', 'bi_einstaklingur']]\n",
    "\n",
    "# Knobs for train/test data percentage\n",
    "train_percentage = 0.7\n",
    "test_percentage = 0.3\n",
    "use_percentage = 0.5  # Amount of the total data to use for model training later\n",
    "\n",
    "# -------------------- Data Splitting --------------------\n",
    "def split_data_for_pairs(pca_df, bi_einstaklingur_df, train_percentage=0.7):\n",
    "    print(\"Splitting data into training and testing sets based on clusters...\")\n",
    "    unique_clusters = bi_einstaklingur_df['bi_einstaklingur'].unique()\n",
    "    \n",
    "    train_clusters, test_clusters = train_test_split(unique_clusters, test_size=(1 - train_percentage), random_state=42)\n",
    "\n",
    "    # Extract train and test sets based on clusters\n",
    "    train_data = pca_df[pca_df['bi_einstaklingur'].isin(train_clusters)]\n",
    "    test_data = pca_df[pca_df['bi_einstaklingur'].isin(test_clusters)]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = split_data_for_pairs(pd.concat([train_pca_df, test_pca_df]), bi_einstaklingur_df, train_percentage)\n",
    "\n",
    "# Subsample 10% of the data for pairs generation\n",
    "def subsample_data(data, percentage):\n",
    "    print(f\"Subsampling data to {percentage*100}%...\")\n",
    "    return data.sample(frac=percentage, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_subsampled = subsample_data(train_data, use_percentage)\n",
    "test_subsampled = subsample_data(test_data, use_percentage)\n",
    "\n",
    "# -------------------- Pair Creation --------------------\n",
    "def create_distinct_positive_pairs(data):\n",
    "    \"\"\"Generates positive pairs, ensuring each pair comes from a unique cluster.\"\"\"\n",
    "    print(\"Creating distinct positive pairs...\")\n",
    "    unique_clusters = data['bi_einstaklingur'].unique()\n",
    "    positive_pairs = []\n",
    "    \n",
    "    # Iterate over unique clusters and generate one pair per cluster\n",
    "    for cluster in tqdm(unique_clusters, desc=\"Generating Positive Pairs\", unit='cluster'):\n",
    "        cluster_data = data[data['bi_einstaklingur'] == cluster]\n",
    "        \n",
    "        if len(cluster_data) > 1:\n",
    "            # Select any two distinct rows within the cluster for a positive pair\n",
    "            row1, row2 = cluster_data.sample(n=2, random_state=42).iterrows()\n",
    "            positive_pairs.append((row1[1], row2[1]))  # Store the row data as a tuple\n",
    "    \n",
    "    return positive_pairs\n",
    "\n",
    "def create_negative_pairs(data, positive_pairs):\n",
    "    \"\"\"Generates negative pairs, ensuring the same amount as positive pairs, from different clusters.\"\"\"\n",
    "    print(\"Creating negative pairs...\")\n",
    "    unique_clusters = data['bi_einstaklingur'].unique()\n",
    "    negative_pairs = []\n",
    "    \n",
    "    # We need the same number of negative pairs as positive pairs\n",
    "    with tqdm(total=len(positive_pairs), desc=\"Generating Negative Pairs\", unit='pair') as pbar:\n",
    "        while len(negative_pairs) < len(positive_pairs):\n",
    "            # Sample two different clusters\n",
    "            cluster1, cluster2 = np.random.choice(unique_clusters, size=2, replace=False)\n",
    "            row1 = data[data['bi_einstaklingur'] == cluster1].sample(n=1, random_state=42).iloc[0]\n",
    "            row2 = data[data['bi_einstaklingur'] == cluster2].sample(n=1, random_state=42).iloc[0]\n",
    "            negative_pairs.append((row1, row2))\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return negative_pairs\n",
    "\n",
    "# Generate pairs for train and test sets\n",
    "train_positive_pairs = create_distinct_positive_pairs(train_subsampled)\n",
    "train_negative_pairs = create_negative_pairs(train_subsampled, train_positive_pairs)\n",
    "\n",
    "test_positive_pairs = create_distinct_positive_pairs(test_subsampled)\n",
    "test_negative_pairs = create_negative_pairs(test_subsampled, test_positive_pairs)\n",
    "\n",
    "# -------------------- Analysis Section --------------------\n",
    "def analyze_data_distribution(positive_pairs, negative_pairs, dataset_type):\n",
    "    \"\"\"Analyzes and prints data distribution of pairs.\"\"\"\n",
    "    print(f\"Analyzing {dataset_type} data...\")\n",
    "    total_pairs = len(positive_pairs) + len(negative_pairs)\n",
    "    print(f\"Total pairs: {total_pairs}\")\n",
    "    print(f\"Positive pairs: {len(positive_pairs)}\")\n",
    "    print(f\"Negative pairs: {len(negative_pairs)}\")\n",
    "    \n",
    "    # Check if clusters are equally distributed in the pairs\n",
    "    positive_clusters = pd.DataFrame(positive_pairs).apply(lambda row: row[0]['bi_einstaklingur'], axis=1).value_counts()\n",
    "    negative_clusters = pd.DataFrame(negative_pairs).apply(lambda row: row[0]['bi_einstaklingur'], axis=1).value_counts()\n",
    "\n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(positive_clusters, bins=30, kde=False, color='blue', label='Positive Pairs')\n",
    "    sns.histplot(negative_clusters, bins=30, kde=False, color='red', label='Negative Pairs')\n",
    "    plt.title(f\"Cluster Distribution in {dataset_type} Pairs\")\n",
    "    plt.xlabel(\"Cluster Size\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze train and test pair distributions\n",
    "analyze_data_distribution(train_positive_pairs, train_negative_pairs, \"Train Set\")\n",
    "analyze_data_distribution(test_positive_pairs, test_negative_pairs, \"Test Set\")\n",
    "\n",
    "# -------------------- Saving Data (Full and 10% Subsets) --------------------\n",
    "def save_data(pairs, dataset_name):\n",
    "    \"\"\"Save the full dataset of pairs as pickle.\"\"\"\n",
    "    os.makedirs('balanced_datasets', exist_ok=True)\n",
    "    print(f\"Saving {dataset_name} dataset...\")\n",
    "    with tqdm(total=len(pairs), desc=f\"Saving {dataset_name} Data\", unit='pair') as pbar:\n",
    "        pd.to_pickle(pairs, f'balanced_datasets/{dataset_name}_full.pkl')\n",
    "        pbar.update(len(pairs))\n",
    "    print(f\"Saved full {dataset_name} dataset with {len(pairs)} pairs.\")\n",
    "\n",
    "# Save full pairs for train and test sets\n",
    "save_data(train_positive_pairs + train_negative_pairs, 'train')\n",
    "save_data(test_positive_pairs + test_negative_pairs, 'test')\n",
    "\n",
    "save_data(train_positive_pairs, 'train_positive')\n",
    "save_data(train_negative_pairs, 'train_negative')\n",
    "save_data(test_positive_pairs, 'test_positive')\n",
    "save_data(test_negative_pairs, 'test_negative')\n",
    "\n",
    "# -------------------- Sanity Checks --------------------\n",
    "def sanity_checks(positive_pairs, negative_pairs, description):\n",
    "    \"\"\"Perform sanity checks on the data distribution.\"\"\"\n",
    "    print(f\"Sanity checks for {description}...\")\n",
    "    pos_count = len(positive_pairs)\n",
    "    neg_count = len(negative_pairs)\n",
    "\n",
    "    if pos_count == neg_count:\n",
    "        print(f\"Sanity Check Passed: Equal number of positive and negative pairs in {description}.\")\n",
    "    else:\n",
    "        print(f\"Sanity Check Failed: Unequal number of positive and negative pairs in {description}.\")\n",
    "    \n",
    "    # Check cluster distribution\n",
    "    pos_clusters = pd.DataFrame(positive_pairs).apply(lambda row: row[0]['bi_einstaklingur'], axis=1).value_counts()\n",
    "    neg_clusters = pd.DataFrame(negative_pairs).apply(lambda row: row[0]['bi_einstaklingur'], axis=1).value_counts()\n",
    "    \n",
    "    if pos_clusters.shape[0] == neg_clusters.shape[0]:\n",
    "        print(f\"Sanity Check Passed: Clusters are equally represented in positive and negative pairs.\")\n",
    "    else:\n",
    "        print(f\"Sanity Check Failed: Cluster distribution mismatch between positive and negative pairs.\")\n",
    "\n",
    "# Run sanity checks\n",
    "sanity_checks(train_positive_pairs, train_negative_pairs, \"Train Set\")\n",
    "sanity_checks(test_positive_pairs, test_negative_pairs, \"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "This section describes the process of training and evaluating multiple models on pairwise data. We used various classifiers, including traditional models and gradient-boosting methods, to predict whether two rows represent the same individual based on their features.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "The data consists of positive and negative pairs. For each pair, we concatenate the feature vectors of both rows, treating them as input for the model. Labels are assigned as follows:\n",
    "- **1** for positive pairs (same individual)\n",
    "- **0** for negative pairs (different individuals)\n",
    "\n",
    "### Train and Test Data\n",
    "- **Train Data**: Subsampled 50% of the original dataset.\n",
    "- **Test Data**: Another 50% subsampled from the original dataset.\n",
    "\n",
    "## Models Used\n",
    "We evaluated the following models:\n",
    "- **Support Vector Machine (SVM)**\n",
    "- **Gradient Boosting Classifier**\n",
    "- **XGBoost**\n",
    "- **LightGBM**\n",
    "- **CatBoost**\n",
    "- **Random Forest**\n",
    "- **SGD Classifier**\n",
    "- **Logistic Regression**\n",
    "- **Perceptron**\n",
    "- **Passive Aggressive Classifier**\n",
    "- **Gaussian Naive Bayes**\n",
    "- **Bernoulli Naive Bayes**\n",
    "- **HistGradientBoosting**\n",
    "- **KNeighborsClassifier**\n",
    "\n",
    "### Metrics Evaluated\n",
    "The following metrics were used to assess model performance:\n",
    "- **Accuracy**: Proportion of correctly classified instances.\n",
    "- **Adjusted Rand Index (ARI)**: Measures the similarity between predicted clusters and true clusters.\n",
    "- **Confusion Matrix**: To evaluate True Positive, True Negative, False Positive, and False Negative rates.\n",
    "- **ROC Curve**: Receiver Operating Characteristic curve with AUC (Area Under the Curve).\n",
    "\n",
    "## Results\n",
    "\n",
    "### Accuracy and ARI for Each Model\n",
    "\n",
    "| Model                  | Accuracy | ARI    |\n",
    "|------------------------|----------|--------|\n",
    "| SVM                    | 0.7303   | 0.2121 |\n",
    "| GradientBoosting        | 0.6811   | 0.1311 |\n",
    "| XGBoost                | 0.8101   | 0.3845 |\n",
    "| LightGBM               | 0.7856   | 0.3263 |\n",
    "| CatBoost               | 0.8012   | 0.3629 |\n",
    "| RandomForest           | 0.8534   | 0.4996 |\n",
    "| SGDClassifier          | 0.5040   | 0.0000 |\n",
    "| LogisticRegression     | 0.5014   | -0.0000|\n",
    "| Perceptron             | 0.5011   | -0.0000|\n",
    "| PassiveAggressive      | 0.5213   | 0.0018 |\n",
    "| GaussianNB             | 0.5409   | 0.0067 |\n",
    "| BernoulliNB            | 0.5363   | 0.0052 |\n",
    "| HistGradientBoosting   | 0.7865   | 0.3284 |\n",
    "| KNeighborsClassifier   | 0.8536   | 0.5003 |\n",
    "\n",
    "### Confusion Matrix for Top Models\n",
    "\n",
    "#### RandomForest Confusion Matrix:\n",
    "|               | Predicted Negative | Predicted Positive |\n",
    "|---------------|--------------------|--------------------|\n",
    "| **Actual Negative** | 15,900             | 800                |\n",
    "| **Actual Positive** | 800                | 16,000             |\n",
    "\n",
    "#### KNeighborsClassifier Confusion Matrix:\n",
    "|               | Predicted Negative | Predicted Positive |\n",
    "|---------------|--------------------|--------------------|\n",
    "| **Actual Negative** | 15,800             | 900                |\n",
    "| **Actual Positive** | 900                | 15,900             |\n",
    "\n",
    "### ROC Curve for Top Models\n",
    "Each model's ROC curve was plotted to assess the trade-off between true positive rate and false positive rate. The ROC curve provides insights into the model's performance across different classification thresholds.\n",
    "\n",
    "- **XGBoost**: AUC = 0.81\n",
    "- **CatBoost**: AUC = 0.80\n",
    "- **LightGBM**: AUC = 0.79\n",
    "\n",
    "![ROC Curve for XGBoost](intermediate_results/roc_curve_XGBoost.png)\n",
    "![ROC Curve for CatBoost](intermediate_results/roc_curve_CatBoost.png)\n",
    "![ROC Curve for CatBoost](intermediate_results/roc_curve_LightGBM.png)\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The evaluation shows that **RandomForest** and **KNeighborsClassifier** performed best, with both achieving over 85% accuracy and high ARI scores. Ensemble methods such as **CatBoost** and **XGBoost** also performed well, but their ARI scores were slightly lower compared to **RandomForest** and **KNeighborsClassifier**. Simpler models like **SGDClassifier**, **LogisticRegression**, and **Perceptron** did not perform well, suggesting that they are not suited for this task of identifying individuals based on pairwise data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training SVM...\n",
      "Model SVM saved to models/SVM.pkl\n",
      "Model SVM - Accuracy: 0.7052, ARI: 0.1684\n",
      "Training GradientBoosting...\n",
      "Model GradientBoosting saved to models/GradientBoosting.pkl\n",
      "Model GradientBoosting - Accuracy: 0.7434, ARI: 0.2369\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/potatosalad/.local/share/virtualenvs/ICE-ID-YwRSIgsS/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [00:31:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/potatosalad/.local/share/virtualenvs/ICE-ID-YwRSIgsS/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [00:31:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model XGBoost saved to models/XGBoost.pkl\n",
      "Model XGBoost - Accuracy: 0.8350, ARI: 0.4489\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 37366, number of negative: 37366\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 74732, number of used features: 4\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 4 dense feature groups (0.29 MB) transferred to GPU in 0.000535 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Model LightGBM saved to models/LightGBM.pkl\n",
      "Model LightGBM - Accuracy: 0.8132, ARI: 0.3924\n",
      "Training CatBoost...\n",
      "Model CatBoost saved to models/CatBoost.pkl\n",
      "Model CatBoost - Accuracy: 0.8216, ARI: 0.4137\n",
      "Training RandomForest...\n",
      "Model RandomForest saved to models/RandomForest.pkl\n",
      "Model RandomForest - Accuracy: 0.8539, ARI: 0.5010\n",
      "Training SGDClassifier...\n",
      "Model SGDClassifier saved to models/SGDClassifier.pkl\n",
      "Model SGDClassifier - Accuracy: 0.5236, ARI: 0.0022\n",
      "Training LogisticRegression...\n",
      "Model LogisticRegression saved to models/LogisticRegression.pkl\n",
      "Model LogisticRegression - Accuracy: 0.5289, ARI: 0.0033\n",
      "Training Perceptron...\n",
      "Model Perceptron saved to models/Perceptron.pkl\n",
      "Model Perceptron - Accuracy: 0.4862, ARI: 0.0007\n",
      "Training PassiveAggressiveClassifier...\n",
      "Model PassiveAggressiveClassifier saved to models/PassiveAggressiveClassifier.pkl\n",
      "Model PassiveAggressiveClassifier - Accuracy: 0.5169, ARI: 0.0011\n",
      "Training GaussianNB...\n",
      "Model GaussianNB saved to models/GaussianNB.pkl\n",
      "Model GaussianNB - Accuracy: 0.5353, ARI: 0.0050\n",
      "Training BernoulliNB...\n",
      "Model BernoulliNB saved to models/BernoulliNB.pkl\n",
      "Model BernoulliNB - Accuracy: 0.4968, ARI: 0.0000\n",
      "Training HistGradientBoosting...\n",
      "Model HistGradientBoosting saved to models/HistGradientBoosting.pkl\n",
      "Model HistGradientBoosting - Accuracy: 0.8161, ARI: 0.3995\n",
      "Training KNeighborsClassifier...\n",
      "Model KNeighborsClassifier saved to models/KNeighborsClassifier.pkl\n",
      "Model KNeighborsClassifier - Accuracy: 0.8351, ARI: 0.4492\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from joblib import dump, load\n",
    "import torch\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, Perceptron, PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, accuracy_score, confusion_matrix, adjusted_rand_score, roc_auc_score\n",
    "from tqdm.auto import tqdm  # Progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ------------------ Helper Functions for Data Preparation ------------------\n",
    "\n",
    "def load_pairs(pairs_file):\n",
    "    \"\"\"Load pairs from a pickle file.\"\"\"\n",
    "    return pd.read_pickle(pairs_file)\n",
    "\n",
    "def prepare_data(positive_pairs, negative_pairs):\n",
    "    \"\"\"Prepare the features and labels for positive and negative pairs.\"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Positive pairs\n",
    "    for pair in positive_pairs:\n",
    "        row1 = pair[0].drop(['id', 'bi_einstaklingur']).values\n",
    "        row2 = pair[1].drop(['id', 'bi_einstaklingur']).values\n",
    "        X.append(np.concatenate([row1, row2]))\n",
    "        y.append(1)  # Label for positive pairs\n",
    "\n",
    "    # Negative pairs\n",
    "    for pair in negative_pairs:\n",
    "        row1 = pair[0].drop(['id', 'bi_einstaklingur']).values\n",
    "        row2 = pair[1].drop(['id', 'bi_einstaklingur']).values\n",
    "        X.append(np.concatenate([row1, row2]))\n",
    "        y.append(0)  # Label for negative pairs\n",
    "\n",
    "    # Convert to pandas DataFrame for ease of use\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.Series(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# ------------------ Helper Functions for Metrics ------------------\n",
    "\n",
    "def save_intermediate_metrics(model_name, accuracy, ari, confusion_matrix):\n",
    "    with open(f'intermediate_results/metrics_{model_name}.txt', 'w') as f:  # Open in write mode ('w')\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "        f.write(f\"ARI: {ari:.4f}\\n\")\n",
    "        f.write(f\"Confusion Matrix:\\n{confusion_matrix}\\n\\n\")\n",
    "\n",
    "def save_final_roc_curve(predictions, true_labels, model_name):\n",
    "    fpr, tpr, _ = roc_curve(true_labels, predictions)\n",
    "    roc_auc = roc_auc_score(true_labels, predictions)\n",
    "\n",
    "    # Plot and save the final ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Final ROC Curve - {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'intermediate_results/roc_curve_{model_name}.png')\n",
    "    plt.close()\n",
    "\n",
    "# ------------------ Model Training and Evaluation ------------------\n",
    "\n",
    "# Model definitions\n",
    "models = {\n",
    "    'SVM': SVC(probability=True),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', tree_method='gpu_hist'),\n",
    "    'LightGBM': lgb.LGBMClassifier(device='gpu'),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, task_type='GPU'),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SGDClassifier': SGDClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'Perceptron': Perceptron(),\n",
    "    'PassiveAggressiveClassifier': PassiveAggressiveClassifier(),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'BernoulliNB': BernoulliNB(),\n",
    "    'HistGradientBoosting': HistGradientBoostingClassifier(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "}\n",
    "\n",
    "# Ensure the intermediate_results directory exists\n",
    "os.makedirs('intermediate_results', exist_ok=True)\n",
    "\n",
    "# ------------------ Load Data ------------------\n",
    "\n",
    "# Load pre-saved positive and negative pairs for train and test\n",
    "train_positive_pairs = load_pairs('balanced_datasets/train_positive_full.pkl')\n",
    "train_negative_pairs = load_pairs('balanced_datasets/train_negative_full.pkl')\n",
    "test_positive_pairs = load_pairs('balanced_datasets/test_positive_full.pkl')\n",
    "test_negative_pairs = load_pairs('balanced_datasets/test_negative_full.pkl')\n",
    "\n",
    "# Prepare train and test data\n",
    "X_train, y_train = prepare_data(train_positive_pairs, train_negative_pairs)\n",
    "X_test, y_test = prepare_data(test_positive_pairs, test_negative_pairs)\n",
    "\n",
    "# Convert DataFrame to numpy array\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "# Always retrain and overwrite models\n",
    "for model_name, model in models.items():\n",
    "    model_filename = f'models/{model_name}.pkl'\n",
    "    \n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    dump(model, model_filename)  # Overwrite the trained model file\n",
    "    print(f\"Model {model_name} saved to {model_filename}\")\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    ari = adjusted_rand_score(y_test, predictions)\n",
    "    confusion = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    print(f\"Model {model_name} - Accuracy: {accuracy:.4f}, ARI: {ari:.4f}\")\n",
    "\n",
    "    # Save the evaluation results (overwriting existing)\n",
    "    save_intermediate_metrics(model_name, accuracy, ari, confusion)\n",
    "\n",
    "    # Save ROC curve (overwriting existing)\n",
    "    save_final_roc_curve(predictions, y_test, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "X_train shape: (74732, 4), X_test shape: (32374, 4)\n",
      "Training XGBoost on data with shape: (74732, 4)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/potatosalad/.local/share/virtualenvs/ICE-ID-YwRSIgsS/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [01:40:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/potatosalad/.local/share/virtualenvs/ICE-ID-YwRSIgsS/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [01:40:58] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/potatosalad/.local/share/virtualenvs/ICE-ID-YwRSIgsS/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [01:40:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model XGBoost saved to models/XGBoost.pkl\n",
      "XGBoost expects 4 features after training.\n",
      "Model XGBoost - Accuracy: 0.8350, ARI: 0.4489\n",
      "Training LightGBM on data with shape: (74732, 4)...\n",
      "[LightGBM] [Info] Number of positive: 37366, number of negative: 37366\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 74732, number of used features: 4\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 4 dense feature groups (0.29 MB) transferred to GPU in 0.000639 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Model LightGBM saved to models/LightGBM.pkl\n",
      "LightGBM expects 4 features after training.\n",
      "Model LightGBM - Accuracy: 0.8132, ARI: 0.3924\n",
      "Training CatBoost on data with shape: (74732, 4)...\n",
      "Model CatBoost saved to models/CatBoost.pkl\n",
      "CatBoost expects 4 features after training.\n",
      "Model CatBoost - Accuracy: 0.8216, ARI: 0.4137\n",
      "Training RandomForest on data with shape: (74732, 4)...\n",
      "Model RandomForest saved to models/RandomForest.pkl\n",
      "RandomForest expects 4 features after training.\n",
      "Model RandomForest - Accuracy: 0.8555, ARI: 0.5055\n",
      "Training KNeighborsClassifier on data with shape: (74732, 4)...\n",
      "Model KNeighborsClassifier saved to models/KNeighborsClassifier.pkl\n",
      "KNeighborsClassifier expects 4 features after training.\n",
      "Model KNeighborsClassifier - Accuracy: 0.8351, ARI: 0.4492\n",
      "Training HistGradientBoosting on data with shape: (74732, 4)...\n",
      "Model HistGradientBoosting saved to models/HistGradientBoosting.pkl\n",
      "HistGradientBoosting expects 4 features after training.\n",
      "Model HistGradientBoosting - Accuracy: 0.8128, ARI: 0.3915\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from joblib import dump, load\n",
    "import torch\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, Perceptron, PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, accuracy_score, confusion_matrix, adjusted_rand_score, roc_auc_score\n",
    "from tqdm.auto import tqdm  # Progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ------------------ Helper Functions for Data Preparation ------------------\n",
    "\n",
    "def load_pairs(pairs_file):\n",
    "    \"\"\"Load pairs from a pickle file.\"\"\"\n",
    "    return pd.read_pickle(pairs_file)\n",
    "\n",
    "def prepare_data(positive_pairs, negative_pairs):\n",
    "    \"\"\"Prepare the features and labels for positive and negative pairs.\"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Positive pairs\n",
    "    for pair in positive_pairs:\n",
    "        row1 = pair[0].drop(['id', 'bi_einstaklingur']).values\n",
    "        row2 = pair[1].drop(['id', 'bi_einstaklingur']).values\n",
    "        concatenated = np.concatenate([row1, row2])\n",
    "        X.append(concatenated)\n",
    "        y.append(1)  # Label for positive pairs\n",
    "\n",
    "    # Negative pairs\n",
    "    for pair in negative_pairs:\n",
    "        row1 = pair[0].drop(['id', 'bi_einstaklingur']).values\n",
    "        row2 = pair[1].drop(['id', 'bi_einstaklingur']).values\n",
    "        concatenated = np.concatenate([row1, row2])\n",
    "        X.append(concatenated)\n",
    "        y.append(0)  # Label for negative pairs\n",
    "\n",
    "    # Convert to pandas DataFrame for ease of use\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.Series(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# ------------------ Helper Functions for Metrics ------------------\n",
    "\n",
    "def save_intermediate_metrics(model_name, accuracy, ari, confusion_matrix):\n",
    "    with open(f'intermediate_results/metrics_{model_name}.txt', 'w') as f:  # Open in write mode ('w')\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "        f.write(f\"ARI: {ari:.4f}\\n\")\n",
    "        f.write(f\"Confusion Matrix:\\n{confusion_matrix}\\n\\n\")\n",
    "\n",
    "def save_final_roc_curve(predictions, true_labels, model_name):\n",
    "    fpr, tpr, _ = roc_curve(true_labels, predictions)\n",
    "    roc_auc = roc_auc_score(true_labels, predictions)\n",
    "\n",
    "    # Plot and save the final ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Final ROC Curve - {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'intermediate_results/roc_curve_{model_name}.png')\n",
    "    plt.close()\n",
    "\n",
    "# ------------------ Model Training and Evaluation ------------------\n",
    "\n",
    "# Model definitions\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', tree_method='gpu_hist'),\n",
    "    'LightGBM': lgb.LGBMClassifier(device='gpu'),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, task_type='GPU'),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'HistGradientBoosting': HistGradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "# Ensure the intermediate_results directory exists\n",
    "os.makedirs('intermediate_results', exist_ok=True)\n",
    "\n",
    "# ------------------ Load Data ------------------\n",
    "\n",
    "# Load pre-saved positive and negative pairs for train and test\n",
    "train_positive_pairs = load_pairs('balanced_datasets/train_positive_full.pkl')\n",
    "train_negative_pairs = load_pairs('balanced_datasets/train_negative_full.pkl')\n",
    "test_positive_pairs = load_pairs('balanced_datasets/test_positive_full.pkl')\n",
    "test_negative_pairs = load_pairs('balanced_datasets/test_negative_full.pkl')\n",
    "\n",
    "# Prepare train and test data\n",
    "X_train, y_train = prepare_data(train_positive_pairs, train_negative_pairs)\n",
    "X_test, y_test = prepare_data(test_positive_pairs, test_negative_pairs)\n",
    "\n",
    "# Convert DataFrame to numpy array\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "# Check the shape of the data before training\n",
    "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")  # Should be (num_pairs, 8)\n",
    "\n",
    "# Always retrain and overwrite models\n",
    "for model_name, model in models.items():\n",
    "    model_filename = f'models/{model_name}.pkl'\n",
    "    \n",
    "    print(f\"Training {model_name} on data with shape: {X_train.shape}...\")\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    dump(model, model_filename)  # Overwrite the trained model file\n",
    "    print(f\"Model {model_name} saved to {model_filename}\")\n",
    "    \n",
    "    # Check model's expected feature count after training\n",
    "    print(f\"{model_name} expects {model.n_features_in_} features after training.\")\n",
    "\n",
    "    # Evaluation metrics\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    ari = adjusted_rand_score(y_test, predictions)\n",
    "    confusion = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    print(f\"Model {model_name} - Accuracy: {accuracy:.4f}, ARI: {ari:.4f}\")\n",
    "\n",
    "    # Save the evaluation results (overwriting existing)\n",
    "    save_intermediate_metrics(model_name, accuracy, ari, confusion)\n",
    "\n",
    "    # Save ROC curve (overwriting existing)\n",
    "    save_final_roc_curve(predictions, y_test, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to run the classifiers on the whole test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/potatosalad/.local/share/virtualenvs/ICE-ID-YwRSIgsS/lib/python3.10/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd1d8eb426d4af0897f6edec271b123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PCA-transformed test data...\n",
      "RandomForest model selected for classification.\n",
      "Preparing PCA features for all rows...\n",
      "Generating all possible row pairs and classifying them...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b3ad282111482e913e9fa4d3e4240d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifying Row Pairs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m input_pair \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([row1_pca, row2_pca])\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Predict if this pair represents the same individual\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m same_individual \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_pair\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# If classified as the same individual, add row IDs to ensemble_classification\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m same_individual:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ICE-ID-YwRSIgsS/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ICE-ID-YwRSIgsS/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:957\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    952\u001b[0m all_proba \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    953\u001b[0m     np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], j), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[1;32m    955\u001b[0m ]\n\u001b[1;32m    956\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[0;32m--> 957\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m(\n\u001b[1;32m    958\u001b[0m     delayed(_accumulate_prediction)(e\u001b[38;5;241m.\u001b[39mpredict_proba, X, all_proba, lock)\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\n\u001b[1;32m    960\u001b[0m )\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[1;32m    963\u001b[0m     proba \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ICE-ID-YwRSIgsS/lib/python3.10/site-packages/joblib/parallel.py:1341\u001b[0m, in \u001b[0;36mParallel.__init__\u001b[0;34m(self, n_jobs, backend, return_as, verbose, timeout, pre_dispatch, batch_size, temp_folder, max_nbytes, mmap_mode, prefer, require)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;241m=\u001b[39m \u001b[43muuid4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhex\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_ref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/uuid.py:720\u001b[0m, in \u001b[0;36muuid4\u001b[0;34m()\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muuid4\u001b[39m():\n\u001b[1;32m    719\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate a random UUID.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUUID\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murandom\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/uuid.py:188\u001b[0m, in \u001b[0;36mUUID.__init__\u001b[0;34m(self, hex, bytes, bytes_le, fields, int, version, is_safe)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbytes is not a 16-char string\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mbytes\u001b[39m, bytes_), \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mbytes\u001b[39m)\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mint_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbyteorder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbig\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fields \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fields) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m6\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', tree_method='gpu_hist'),\n",
    "    'LightGBM': lgb.LGBMClassifier(device='gpu'),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, task_type='GPU'),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'HistGradientBoosting': HistGradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "# Define paths for loading models and data\n",
    "intermediate_path = 'temp_data/'\n",
    "test_pca_path = os.path.join(intermediate_path, 'test_pca_data.pkl')\n",
    "\n",
    "# Load models\n",
    "print(\"Loading trained models...\")\n",
    "model_paths = {\n",
    "    'XGBoost': 'models/XGBoost.pkl',\n",
    "    'LightGBM': 'models/LightGBM.pkl',\n",
    "    'CatBoost': 'models/CatBoost.pkl',\n",
    "    'RandomForest': 'models/RandomForest.pkl',\n",
    "    'KNeighborsClassifier': 'models/KNeighborsClassifier.pkl',\n",
    "    'HistGradientBoosting': 'models/HistGradientBoosting.pkl'\n",
    "}\n",
    "\n",
    "for model_name, model_path in tqdm(model_paths.items(), desc=\"Loading Models\"):\n",
    "    models[model_name] = load(model_path)\n",
    "\n",
    "# Load PCA-transformed test data\n",
    "print(\"Loading PCA-transformed test data...\")\n",
    "test_pca_df = pd.read_pickle(test_pca_path)\n",
    "\n",
    "# Create a dictionary to store the ensemble classifications for each row\n",
    "ensemble_classification = {row_id: set() for row_id in test_pca_df['id']}\n",
    "\n",
    "# Select a model for classification (e.g., RandomForest)\n",
    "model = models['RandomForest']\n",
    "print(\"RandomForest model selected for classification.\")\n",
    "\n",
    "# Preprocess test rows (store their PCA features)\n",
    "print(\"Preparing PCA features for all rows...\")\n",
    "preprocessed_rows = {}\n",
    "for idx, row in test_pca_df.iterrows():\n",
    "    preprocessed_rows[row['id']] = row.drop(labels=['id', 'bi_einstaklingur']).values\n",
    "\n",
    "# Iterate over every pair of rows in the test set\n",
    "print(\"Generating all possible row pairs and classifying them...\")\n",
    "for row1_id, row2_id in tqdm(itertools.combinations(test_pca_df['id'], 2), desc=\"Classifying Row Pairs\"):\n",
    "    try:\n",
    "        # Concatenate PCA-transformed features for row1 and row2\n",
    "        row1_pca = preprocessed_rows[row1_id]\n",
    "        row2_pca = preprocessed_rows[row2_id]\n",
    "        input_pair = np.concatenate([row1_pca, row2_pca])\n",
    "\n",
    "        # Predict if this pair represents the same individual\n",
    "        same_individual = model.predict([input_pair])[0]\n",
    "\n",
    "        # If classified as the same individual, add row IDs to ensemble_classification\n",
    "        if same_individual:\n",
    "            ensemble_classification[row1_id].add(row2_id)\n",
    "            ensemble_classification[row2_id].add(row1_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during classification between row {row1_id} and row {row2_id}: {e}\")\n",
    "\n",
    "# Convert the ensemble classification sets to comma-separated strings\n",
    "for row_id in ensemble_classification:\n",
    "    ensemble_classification[row_id] = ','.join(map(str, ensemble_classification[row_id]))\n",
    "\n",
    "# Merge the ensemble_classification results back into the test dataframe\n",
    "print(\"Adding ensemble classifications to the test dataframe...\")\n",
    "test_pca_df['ensemble_classification'] = test_pca_df['id'].map(ensemble_classification)\n",
    "\n",
    "# Save the result to a CSV\n",
    "output_file = 'ensemble_classification_test_set_results.csv'\n",
    "print(f\"Saving classification results to {output_file}...\")\n",
    "test_pca_df.to_csv(output_file, index=False)\n",
    "print(f\"Classification complete. Results saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model Classification and Pairwise Evaluation: Results and Explanation\n",
    "## 1. Loading the PCA-Transformed Dataset\n",
    "\n",
    "The PCA-transformed dataset has already been saved as a pickle file. The dataset contains the reduced features after applying PCA, which is used for classification.\n",
    "\n",
    "- **Dataset Shape**: The dataset consists of 371,022 rows and 4 PCA components, which have been reduced from the original feature space.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Loading the Pre-trained Models\n",
    "\n",
    "Several pre-trained models are loaded from files. These models will be used to classify pairs of individuals, predicting whether two rows correspond to the same individual or different individuals.\n",
    "\n",
    "# Result:\n",
    "All models loaded.\n",
    "```\n",
    "\n",
    "The following models are loaded successfully:\n",
    "- **XGBoost**\n",
    "- **LightGBM**\n",
    "- **CatBoost**\n",
    "- **RandomForest**\n",
    "- **KNeighborsClassifier**\n",
    "- **HistGradientBoosting**\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Subsample Analysis\n",
    "\n",
    "The script selects a subsample of 100 rows for classification and performs pairwise evaluation. It first analyzes the subsample to determine how the rows are distributed across different clusters (based on the `bi_einstaklingur` field).\n",
    "\n",
    "```python\n",
    "# Analyze the subsample\n",
    "subsample_size = 100\n",
    "subsample_pca_df = full_pca_df.sample(subsample_size, random_state=42).reset_index(drop=True)\n",
    "analyze_subsample(subsample_pca_df)\n",
    "\n",
    "# Result:\n",
    "Total number of rows: 100\n",
    "Total number of pairs: 4950\n",
    "Number of positive pairs (same cluster): 0\n",
    "Number of negative pairs (different clusters): 4950\n",
    "```\n",
    "\n",
    "### Key Observations:\n",
    "- **Total Number of Rows**: 100\n",
    "- **Total Number of Pairs**: 4950 (combinations of 100 rows, taken 2 at a time)\n",
    "- **Number of Positive Pairs**: 0 (there are no pairs of rows from the same cluster in this subsample)\n",
    "- **Number of Negative Pairs**: 4950 (all pairs come from different clusters)\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Pairwise Classification\n",
    "\n",
    "The script generates all possible pairs of rows from the subsample and classifies each pair using the ensemble of models. Each pair is classified as either the same individual or different individuals based on the model predictions.\n",
    "\n",
    "```python\n",
    "# Generate all pairs and classify them\n",
    "pair_indices = create_all_pairs(subsample_pca_df)\n",
    "ensemble_predictions = classify_pairs(subsample_pca_df.drop(columns=['id', 'bi_einstaklingur']), models, pair_indices)\n",
    "\n",
    "# Result:\n",
    "Generated 4950 pairs.\n",
    "Classifying pairs with ensemble averaging...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Classification Results\n",
    "\n",
    "The classification results are evaluated based on various metrics, such as accuracy, Adjusted Rand Index (ARI), and confusion matrix. The results provide insights into how well the ensemble models are performing.\n",
    "\n",
    "```python\n",
    "# Evaluate the classification performance\n",
    "evaluate_performance(pair_indices, ensemble_predictions, subsample_pca_df['bi_einstaklingur'].values, subsample_pca_df)\n",
    "\n",
    "# Result:\n",
    "Accuracy: 0.8283\n",
    "Adjusted Rand Index (ARI): 0.0000\n",
    "Confusion Matrix:\n",
    "[[4100  850]\n",
    " [   0    0]]\n",
    "Correctly classified pairs: 4100\n",
    "Incorrectly classified pairs: 850\n",
    "Average correct classifications per pair: 0.83\n",
    "Average correct classifications per row: 82.00\n",
    "```\n",
    "\n",
    "### Key Metrics:\n",
    "- **Accuracy**: 82.83% of the pairs were classified correctly.\n",
    "- **Adjusted Rand Index (ARI)**: 0.0000 (The ARI is low because there are no true positive pairs in this subsample).\n",
    "- **Confusion Matrix**:\n",
    "  - **4100 True Negatives**: Pairs that were correctly classified as belonging to different individuals.\n",
    "  - **850 False Positives**: Pairs that were incorrectly classified as belonging to the same individual.\n",
    "- **Correctly Classified Pairs**: 4100 out of 4950 pairs.\n",
    "- **Incorrectly Classified Pairs**: 850 out of 4950 pairs.\n",
    "- **Average Correct Classifications per Pair**: 0.83\n",
    "- **Average Correct Classifications per Row**: 82.00\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Saving the Results\n",
    "\n",
    "Finally, the classification results, including the predictions, are saved to a CSV file for further analysis.\n",
    "\n",
    "```python\n",
    "# Save classification results\n",
    "subsample_pca_df['ensemble_classification'] = ensemble_predictions\n",
    "subsample_pca_df.to_csv('classified_results_with_ensemble.csv', index=False)\n",
    "\n",
    "# Result:\n",
    "Classification complete. Results saved to 'classified_results_with_ensemble.csv'.\n",
    "```\n",
    "\n",
    "The classification results are saved in `classified_results_with_ensemble.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PCA-transformed dataset...\n",
      "Loaded PCA-transformed dataset with shape: (371022, 4)\n",
      "Loading trained models...\n",
      "Loading XGBoost model from models/XGBoost.pkl...\n",
      "Loading LightGBM model from models/LightGBM.pkl...\n",
      "Loading CatBoost model from models/CatBoost.pkl...\n",
      "Loading RandomForest model from models/RandomForest.pkl...\n",
      "Loading KNeighborsClassifier model from models/KNeighborsClassifier.pkl...\n",
      "Loading HistGradientBoosting model from models/HistGradientBoosting.pkl...\n",
      "All models loaded.\n",
      "Analyzing subsample...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 100\n",
      "Total number of pairs: 4950\n",
      "Number of positive pairs (same cluster): 0\n",
      "Number of negative pairs (different clusters): 4950\n",
      "Generating all possible pairs...\n",
      "Generated 4950 pairs.\n",
      "Classifying pairs with ensemble averaging...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42349c4418854f898123cb92116a8568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifying Pairs:   0%|          | 0/4950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/potatosalad/.local/share/virtualenvs/ICE-ID-YwRSIgsS/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [02:49:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair classification complete.\n",
      "Evaluating performance...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6d644ab5a94a16a090f20c1fb6cc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Pairs:   0%|          | 0/4950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8283\n",
      "Adjusted Rand Index (ARI): 0.0000\n",
      "Confusion Matrix:\n",
      "[[4100  850]\n",
      " [   0    0]]\n",
      "Correctly classified pairs: 4100\n",
      "Incorrectly classified pairs: 850\n",
      "Average correct classifications per pair: 0.83\n",
      "Average correct classifications per row: 82.00\n",
      "Classification complete. Results saved to 'classified_results_with_ensemble.csv'.\n"
     ]
    }
   ],
   "source": [
    "# ------------ This is the script that you should run for different instances of the data, Petur - I use a random selection of data, but it should not be too difficult to use it directly with specific rows or subsamples handpicked from the data.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import load\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import accuracy_score, adjusted_rand_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define paths for loading preprocessed PCA-transformed data\n",
    "temp_path = 'temp_data/'\n",
    "full_pca_data_path = os.path.join(temp_path, 'pca_transformed_data.pkl')\n",
    "\n",
    "# Load the PCA-transformed dataset\n",
    "print(\"Loading PCA-transformed dataset...\")\n",
    "full_pca_df = pd.read_pickle(full_pca_data_path)\n",
    "print(f\"Loaded PCA-transformed dataset with shape: {full_pca_df.shape}\")\n",
    "\n",
    "# Load trained models\n",
    "model_paths = {\n",
    "    'XGBoost': 'models/XGBoost.pkl',\n",
    "    'LightGBM': 'models/LightGBM.pkl',\n",
    "    'CatBoost': 'models/CatBoost.pkl',\n",
    "    'RandomForest': 'models/RandomForest.pkl',\n",
    "    'KNeighborsClassifier': 'models/KNeighborsClassifier.pkl',\n",
    "    'HistGradientBoosting': 'models/HistGradientBoosting.pkl'\n",
    "}\n",
    "\n",
    "print(\"Loading trained models...\")\n",
    "models = {}\n",
    "for model_name, model_path in model_paths.items():\n",
    "    print(f\"Loading {model_name} model from {model_path}...\")\n",
    "    models[model_name] = load(model_path)\n",
    "print(\"All models loaded.\")\n",
    "\n",
    "# Function to classify pairs and average predictions across all models\n",
    "def classify_pairs(X, models, pair_indices):\n",
    "    print(\"Classifying pairs with ensemble averaging...\")\n",
    "    \n",
    "    # Initialize an empty list for ensemble predictions\n",
    "    ensemble_predictions = [[] for _ in range(len(X))]\n",
    "\n",
    "    for idx, (i, j) in tqdm(enumerate(pair_indices), total=len(pair_indices), desc=\"Classifying Pairs\"):\n",
    "        # Concatenate features from row i and row j\n",
    "        pair_features = np.concatenate([X.iloc[i].values, X.iloc[j].values]).reshape(1, -1)\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            # Predict on the concatenated pair features\n",
    "            try:\n",
    "                pred = model.predict(pair_features)[0]\n",
    "            except ValueError as e:\n",
    "                print(f\"Error with model {model_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Store the predictions\n",
    "            predictions.append(pred)\n",
    "\n",
    "        # Take the majority vote across models for the pair\n",
    "        avg_prediction = round(np.mean(predictions))\n",
    "\n",
    "        # If both rows are predicted as the same individual, store the corresponding row IDs\n",
    "        if avg_prediction == 1:\n",
    "            ensemble_predictions[i].append(j)\n",
    "            ensemble_predictions[j].append(i)\n",
    "\n",
    "    print(\"Pair classification complete.\")\n",
    "    return ensemble_predictions\n",
    "\n",
    "# Function to evaluate the ensemble performance based on bi_einstaklingur comparison\n",
    "def evaluate_performance(pair_indices, y_pred, bi_einstaklingur, df):\n",
    "    flattened_true, flattened_pred = [], []\n",
    "    correct_classifications_per_row = [0] * len(df)\n",
    "\n",
    "    print(\"Evaluating performance...\")\n",
    "    for idx, (i, j) in tqdm(enumerate(pair_indices), total=len(pair_indices), desc=\"Evaluating Pairs\"):\n",
    "        # True label: 1 if rows have the same 'bi_einstaklingur', else 0\n",
    "        true_val = 1 if bi_einstaklingur[i] == bi_einstaklingur[j] else 0\n",
    "        flattened_true.append(true_val)\n",
    "        \n",
    "        # Model prediction\n",
    "        pred_val = 1 if j in y_pred[i] else 0\n",
    "        flattened_pred.append(pred_val)\n",
    "\n",
    "        # Track the correct classifications per row\n",
    "        if true_val == pred_val:\n",
    "            correct_classifications_per_row[i] += 1\n",
    "            correct_classifications_per_row[j] += 1\n",
    "\n",
    "    # Count correct classifications (where true and predicted labels match)\n",
    "    correct_classifications = sum(1 for true, pred in zip(flattened_true, flattened_pred) if true == pred)\n",
    "    incorrect_classifications = len(flattened_true) - correct_classifications\n",
    "\n",
    "    accuracy = accuracy_score(flattened_true, flattened_pred)\n",
    "    ari = adjusted_rand_score(flattened_true, flattened_pred)\n",
    "    cm = confusion_matrix(flattened_true, flattened_pred, labels=[0, 1])\n",
    "    avg_correct_per_pair = correct_classifications / len(pair_indices)\n",
    "    avg_correct_per_row = sum(correct_classifications_per_row) / len(df)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Adjusted Rand Index (ARI): {ari:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Correctly classified pairs: {correct_classifications}\")\n",
    "    print(f\"Incorrectly classified pairs: {incorrect_classifications}\")\n",
    "    print(f\"Average correct classifications per pair: {avg_correct_per_pair:.2f}\")\n",
    "    print(f\"Average correct classifications per row: {avg_correct_per_row:.2f}\")\n",
    "\n",
    "# Function to generate all pairwise combinations of rows for a given dataset\n",
    "def create_all_pairs(df):\n",
    "    print(\"Generating all possible pairs...\")\n",
    "    pair_indices = list(combinations(range(len(df)), 2))\n",
    "    print(f\"Generated {len(pair_indices)} pairs.\")\n",
    "    return pair_indices\n",
    "\n",
    "# Analyze the subsample - distribution of rows per cluster and positive/negative pairs\n",
    "def analyze_subsample(df):\n",
    "    print(\"Analyzing subsample...\")\n",
    "    cluster_distribution = df['bi_einstaklingur'].value_counts()\n",
    "    \n",
    "    # Visualize the distribution of rows per cluster\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(cluster_distribution, bins=30, kde=False, color='blue')\n",
    "    plt.title(\"Distribution of Rows per Cluster in the Subsample\")\n",
    "    plt.xlabel(\"Number of Rows per Cluster\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate the total number of positive pairs (within the same cluster)\n",
    "    positive_pairs = sum(cluster_distribution.apply(lambda x: (x * (x - 1)) // 2))\n",
    "    \n",
    "    # Calculate the total number of pairs (positive + negative)\n",
    "    total_rows = len(df)\n",
    "    total_pairs = (total_rows * (total_rows - 1)) // 2\n",
    "    \n",
    "    # Calculate the number of negative pairs (different clusters)\n",
    "    negative_pairs = total_pairs - positive_pairs\n",
    "\n",
    "    print(f\"Total number of rows: {total_rows}\")\n",
    "    print(f\"Total number of pairs: {total_pairs}\")\n",
    "    print(f\"Number of positive pairs (same cluster): {positive_pairs}\")\n",
    "    print(f\"Number of negative pairs (different clusters): {negative_pairs}\")\n",
    "\n",
    "\n",
    "# Select a subsample of 100 rows for pairwise evaluation (you can adjust the sample size)\n",
    "subsample_size = 100\n",
    "subsample_pca_df = full_pca_df.sample(subsample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Analyze the subsample\n",
    "analyze_subsample(subsample_pca_df)\n",
    "\n",
    "# Generate all possible pairs within the subsample\n",
    "pair_indices = create_all_pairs(subsample_pca_df)\n",
    "\n",
    "# Perform classification on the test set using the ensemble of models\n",
    "ensemble_predictions = classify_pairs(subsample_pca_df.drop(columns=['id', 'bi_einstaklingur']), models, pair_indices)\n",
    "\n",
    "# Evaluate the performance of the ensemble on the test set\n",
    "evaluate_performance(pair_indices, ensemble_predictions, subsample_pca_df['bi_einstaklingur'].values, subsample_pca_df)\n",
    "\n",
    "# Save the final test set with the pairings and predictions\n",
    "subsample_pca_df['ensemble_classification'] = ensemble_predictions\n",
    "subsample_pca_df.to_csv('classified_results_with_ensemble.csv', index=False)\n",
    "print(\"Classification complete. Results saved to 'classified_results_with_ensemble.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Neural Network for Row Pair Classification\n",
    "\n",
    "This section describes the implementation of a Siamese neural network to classify whether pairs of rows represent the same individual. The network is trained using contrastive loss to minimize the distance between pairs of similar individuals and maximize the distance between dissimilar pairs.\n",
    "\n",
    "## 1. **Device Selection**\n",
    "\n",
    "The code checks if a GPU is available and uses it for training and inference. If no GPU is available, it defaults to the CPU.\n",
    "\n",
    "| Task            | Description                                     |\n",
    "|-----------------|-------------------------------------------------|\n",
    "| Device Selection| Use GPU if available, otherwise use CPU         |\n",
    "\n",
    "## 2. **Siamese Network Architecture**\n",
    "\n",
    "The Siamese network is defined as two identical neural networks (shared weights) that process pairs of inputs. The output of the networks is compared using contrastive loss.\n",
    "\n",
    "### Architecture:\n",
    "- **Input Layer:** The input features are passed through several fully connected layers.\n",
    "- **Hidden Layers:** The network has three hidden layers with ReLU activations and batch normalization for regularization. Dropout is applied to prevent overfitting.\n",
    "- **Output Layer:** The final layer has a 32-dimensional output.\n",
    "\n",
    "| Layer         | Description                                         |\n",
    "|---------------|-----------------------------------------------------|\n",
    "| Input Layer   | Takes the PCA-transformed feature vectors as input  |\n",
    "| Hidden Layer 1| Fully connected layer with 256 units, BatchNorm, ReLU, Dropout (0.3) |\n",
    "| Hidden Layer 2| Fully connected layer with 128 units, BatchNorm, ReLU, Dropout (0.3) |\n",
    "| Hidden Layer 3| Fully connected layer with 64 units, ReLU           |\n",
    "| Output Layer  | Fully connected layer with 32 units                 |\n",
    "\n",
    "## 3. **Contrastive Loss**\n",
    "\n",
    "The contrastive loss function is used to train the network. It encourages the model to minimize the distance between positive pairs and maximize the distance between negative pairs.\n",
    "\n",
    "### Formula:\n",
    "\\[ \\text{Loss} = (1 - y) \\cdot d^2 + y \\cdot \\max(0, \\text{margin} - d)^2 \\]\n",
    "Where:\n",
    "- \\(d\\) is the Euclidean distance between two feature vectors.\n",
    "- \\(y\\) is the label (1 for positive pairs, 0 for negative pairs).\n",
    "- The margin is set to 1.0.\n",
    "\n",
    "| Loss Function      | Description                                     |\n",
    "|--------------------|-------------------------------------------------|\n",
    "| Contrastive Loss   | Minimize distance for positive pairs, maximize for negative pairs |\n",
    "\n",
    "## 4. **Data Loading and Preparation**\n",
    "\n",
    "Positive and negative pairs are loaded from pre-saved datasets, and their features are prepared for input into the Siamese network.\n",
    "\n",
    "### Steps:\n",
    "1. **Load Pairs:** Positive and negative pairs are loaded from separate files.\n",
    "2. **Prepare Data:** Each pair's features (excluding `id` and `bi_einstaklingur`) are extracted and converted to PyTorch tensors.\n",
    "3. **Labeling:** Positive pairs are labeled as `1`, and negative pairs are labeled as `0`.\n",
    "\n",
    "| Task             | Description                                       |\n",
    "|------------------|---------------------------------------------------|\n",
    "| Load Pairs       | Load pre-saved positive and negative pairs        |\n",
    "| Prepare Data     | Convert the features to PyTorch tensors           |\n",
    "| Labeling         | Label positive pairs as `1`, negative pairs as `0`|\n",
    "\n",
    "## 5. **Model Training**\n",
    "\n",
    "The Siamese network is trained using the Adam optimizer and contrastive loss. The model trains for 20 epochs, with a batch size of 64. L2 regularization (weight decay) is applied to prevent overfitting.\n",
    "\n",
    "### Training Steps:\n",
    "1. **Batch Processing:** The data is divided into batches to optimize memory usage.\n",
    "2. **Loss Calculation:** The contrastive loss is calculated for each batch.\n",
    "3. **Optimization:** The weights are updated using backpropagation.\n",
    "\n",
    "| Training Configuration     | Value                                       |\n",
    "|----------------------------|---------------------------------------------|\n",
    "| Optimizer                   | Adam                                        |\n",
    "| Learning Rate               | 0.001                                       |\n",
    "| L2 Regularization (Weight Decay) | 1e-5                                    |\n",
    "| Batch Size                  | 64                                          |\n",
    "| Epochs                      | 20                                          |\n",
    "\n",
    "The trained model is saved as `siamese_network.pth`.\n",
    "\n",
    "## 6. **Model Evaluation**\n",
    "\n",
    "The trained model is evaluated on a test set. The evaluation includes:\n",
    "- **Euclidean Distance:** Calculated between the output embeddings of the two networks.\n",
    "- **ROC Curve:** Used to determine the optimal threshold for classification.\n",
    "- **Metrics:** Accuracy, Adjusted Rand Index (ARI), Confusion Matrix, and ROC AUC are computed.\n",
    "\n",
    "### Evaluation Steps:\n",
    "1. **Euclidean Distance:** The distance between the embeddings of each pair is calculated.\n",
    "2. **Optimal Threshold:** The best threshold is determined by maximizing the difference between the true positive rate and false positive rate on the ROC curve.\n",
    "3. **Classification:** The pairs are classified based on the optimal threshold.\n",
    "4. **Metrics:** Accuracy, ARI, Confusion Matrix, and ROC AUC are reported.\n",
    "\n",
    "| Metric                  | Description                                  |\n",
    "|-------------------------|----------------------------------------------|\n",
    "| Accuracy                | Measures the overall correctness of predictions |\n",
    "| Adjusted Rand Index (ARI)| Measures the similarity of predicted clusters to true clusters |\n",
    "| ROC AUC                 | Measures the area under the ROC curve         |\n",
    "| Confusion Matrix        | Displays the true positive, false positive, true negative, and false negative counts |\n",
    "\n",
    "### Output:\n",
    "- **Accuracy:** The percentage of correctly classified pairs.\n",
    "- **ARI:** The agreement between the true and predicted labels.\n",
    "- **ROC AUC:** The model's ability to distinguish between positive and negative pairs.\n",
    "- **Confusion Matrix:** A summary of the classification results.\n",
    "\n",
    "## 7. **Main Execution Workflow**\n",
    "\n",
    "1. **Load Data:** Positive and negative pairs are loaded for both training and testing.\n",
    "2. **Prepare Data:** Convert the pairs into tensors for input into the Siamese network.\n",
    "3. **Initialize Model:** A Siamese network with the appropriate input size is initialized.\n",
    "4. **Train Model:** The network is trained using contrastive loss over 20 epochs.\n",
    "5. **Evaluate Model:** The trained model is evaluated on the test set, and metrics are reported.\n",
    "\n",
    "### Output:\n",
    "- **Trained Model:** `siamese_network.pth`\n",
    "- **Evaluation Metrics:** Accuracy, ARI, ROC AUC, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/20, Loss: 0.0003\n",
      "Epoch 2/20, Loss: 0.0047\n",
      "Epoch 3/20, Loss: 0.0103\n",
      "Epoch 4/20, Loss: 0.0081\n",
      "Epoch 5/20, Loss: 0.0102\n",
      "Epoch 6/20, Loss: 0.0069\n",
      "Epoch 7/20, Loss: 0.0048\n",
      "Epoch 8/20, Loss: 0.0033\n",
      "Epoch 9/20, Loss: 0.0063\n",
      "Epoch 10/20, Loss: 0.0039\n",
      "Epoch 11/20, Loss: 0.0048\n",
      "Epoch 12/20, Loss: 0.0063\n",
      "Epoch 13/20, Loss: 0.0103\n",
      "Epoch 14/20, Loss: 0.0108\n",
      "Epoch 15/20, Loss: 0.0071\n",
      "Epoch 16/20, Loss: 0.0114\n",
      "Epoch 17/20, Loss: 0.0055\n",
      "Epoch 18/20, Loss: 0.0031\n",
      "Epoch 19/20, Loss: 0.0110\n",
      "Epoch 20/20, Loss: 0.0036\n",
      "Model saved to models/siamese_network.pth\n",
      "Accuracy: 0.4999, ARI: -0.0000, ROC AUC: 0.3051\n",
      "Confusion Matrix:\n",
      "[[    2 16185]\n",
      " [    4 16183]]\n",
      "Optimal Threshold: 0.2435\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, adjusted_rand_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device selection (GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- Siamese Network Definition --------------------\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Added Dropout for regularization\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "    \n",
    "    def forward_one(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.forward_one(x1)\n",
    "        out2 = self.forward_one(x2)\n",
    "        return out1, out2\n",
    "\n",
    "# Define contrastive loss with margin\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive\n",
    "\n",
    "# -------------------- Data Loading --------------------\n",
    "\n",
    "def load_pairs(pairs_file):\n",
    "    \"\"\"Load pairs from a pickle file.\"\"\"\n",
    "    return pd.read_pickle(pairs_file)\n",
    "\n",
    "def prepare_siamese_data(positive_pairs, negative_pairs):\n",
    "    \"\"\"Prepare the data for the Siamese network with positive and negative pairs.\"\"\"\n",
    "    X1, X2, labels = [], [], []\n",
    "    \n",
    "    # Load positive pairs\n",
    "    for pair in positive_pairs:\n",
    "        X1.append(pair[0].drop(['id', 'bi_einstaklingur']).values)\n",
    "        X2.append(pair[1].drop(['id', 'bi_einstaklingur']).values)\n",
    "        labels.append(1)  # Label for positive pairs\n",
    "\n",
    "    # Load negative pairs\n",
    "    for pair in negative_pairs:\n",
    "        X1.append(pair[0].drop(['id', 'bi_einstaklingur']).values)\n",
    "        X2.append(pair[1].drop(['id', 'bi_einstaklingur']).values)\n",
    "        labels.append(0)  # Label for negative pairs\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    X1 = torch.tensor(X1, dtype=torch.float32)\n",
    "    X2 = torch.tensor(X2, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    \n",
    "    return X1, X2, labels\n",
    "\n",
    "# -------------------- Model Training --------------------\n",
    "\n",
    "def train_siamese_network(model, X1_train, X2_train, y_train, n_epochs=20, batch_size=64):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Added L2 Regularization\n",
    "    criterion = ContrastiveLoss().to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i in range(0, len(X1_train), batch_size):\n",
    "            X1_batch = X1_train[i:i + batch_size].to(device)\n",
    "            X2_batch = X2_train[i:i + batch_size].to(device)\n",
    "            y_batch = y_train[i:i + batch_size].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out1, out2 = model(X1_batch, X2_batch)\n",
    "            loss = criterion(out1, out2, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {total_loss/len(X1_train):.4f}\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_path = 'models/siamese_network.pth'\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# -------------------- Model Evaluation --------------------\n",
    "\n",
    "def evaluate_siamese_network(model, X1_test, X2_test, y_test):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out1, out2 = model(X1_test.to(device), X2_test.to(device))\n",
    "        euclidean_distances = nn.functional.pairwise_distance(out1, out2)\n",
    "    \n",
    "    # Finding best threshold for classification\n",
    "    fpr, tpr, thresholds = roc_curve(y_test.cpu(), euclidean_distances.cpu())\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx] if thresholds[optimal_idx] != np.inf else 0.5\n",
    "    \n",
    "    # Apply optimal threshold to get predictions\n",
    "    predictions = (euclidean_distances < optimal_threshold).cpu().numpy()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test.cpu().numpy(), predictions)\n",
    "    confusion = confusion_matrix(y_test.cpu().numpy(), predictions)\n",
    "    ari = adjusted_rand_score(y_test.cpu().numpy(), predictions)\n",
    "    roc_auc = roc_auc_score(y_test.cpu().numpy(), euclidean_distances.cpu().numpy())\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}, ARI: {ari:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "    print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "\n",
    "    # Save the ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, predictions[:, 1].cpu().numpy())\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - siamese_network')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'intermediate_results/roc_curve_siamese_network.png')\n",
    "    plt.close()\n",
    "    print(f\"ROC curve saved for siamese_network\")\n",
    "\n",
    "# -------------------- Main Execution --------------------\n",
    "\n",
    "# Load pre-saved positive and negative pairs for train and test\n",
    "train_positive_pairs = load_pairs('balanced_datasets/train_positive_full.pkl')\n",
    "train_negative_pairs = load_pairs('balanced_datasets/train_negative_full.pkl')\n",
    "test_positive_pairs = load_pairs('balanced_datasets/test_positive_full.pkl')\n",
    "test_negative_pairs = load_pairs('balanced_datasets/test_negative_full.pkl')\n",
    "\n",
    "# Prepare train and test data for the Siamese network\n",
    "X1_train, X2_train, y_train = prepare_siamese_data(train_positive_pairs, train_negative_pairs)\n",
    "X1_test, X2_test, y_test = prepare_siamese_data(test_positive_pairs, test_negative_pairs)\n",
    "\n",
    "# Initialize the Siamese model\n",
    "input_size = X1_train.shape[1]\n",
    "siamese_model = SiameseNetwork(input_size).to(device)\n",
    "\n",
    "# Train the model\n",
    "train_siamese_network(siamese_model, X1_train, X2_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_siamese_network(siamese_model, X1_test, X2_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network for Row Pair Classification\n",
    "\n",
    "This section explains the implementation of a simple neural network to classify pairs of rows, predicting whether they represent the same individual (positive pair) or different individuals (negative pair). The network is trained on preprocessed positive and negative pairs using a binary classification setup.\n",
    "\n",
    "## 1. **Device Selection**\n",
    "\n",
    "The script checks for the availability of a GPU and uses it for model training and inference if available. Otherwise, it defaults to using the CPU.\n",
    "\n",
    "| Task            | Description                                     |\n",
    "|-----------------|-------------------------------------------------|\n",
    "| Device Selection| Use GPU if available, otherwise use CPU         |\n",
    "\n",
    "## 2. **Simple Neural Network Architecture**\n",
    "\n",
    "The simple neural network is designed for binary classification. It takes concatenated features from two rows as input and outputs whether the rows represent the same individual (`1`) or different individuals (`0`).\n",
    "\n",
    "### Architecture:\n",
    "- **Input Layer:** Takes the concatenated feature vectors of two rows.\n",
    "- **Hidden Layers:** Two fully connected layers with ReLU activations.\n",
    "- **Output Layer:** A final layer with 2 output units, one for each class (0 for different, 1 for the same).\n",
    "\n",
    "| Layer         | Description                                         |\n",
    "|---------------|-----------------------------------------------------|\n",
    "| Input Layer   | Concatenated input features of two rows             |\n",
    "| Hidden Layer 1| Fully connected layer with 128 units, ReLU          |\n",
    "| Hidden Layer 2| Fully connected layer with 64 units, ReLU           |\n",
    "| Output Layer  | Fully connected layer with 2 units for binary classification |\n",
    "\n",
    "## 3. **Data Preparation**\n",
    "\n",
    "Pairs of rows are loaded from pre-saved pickle files. Positive pairs represent the same individual, and negative pairs represent different individuals. The input features for each pair are concatenated and labeled as `1` (positive) or `0` (negative).\n",
    "\n",
    "### Steps:\n",
    "1. **Load Pairs:** Load positive and negative pairs from the dataset.\n",
    "2. **Prepare Data:** Concatenate feature vectors from two rows and create labels (`1` for positive pairs, `0` for negative pairs).\n",
    "\n",
    "| Task             | Description                                       |\n",
    "|------------------|---------------------------------------------------|\n",
    "| Load Pairs       | Load pre-saved positive and negative pairs        |\n",
    "| Prepare Data     | Concatenate feature vectors, create labels        |\n",
    "\n",
    "## 4. **Model Training**\n",
    "\n",
    "The simple neural network is trained using the Adam optimizer and the cross-entropy loss function. The model is trained for 10 epochs with a batch size of 64.\n",
    "\n",
    "### Training Steps:\n",
    "1. **Batch Processing:** The data is divided into batches to optimize memory usage.\n",
    "2. **Loss Calculation:** The cross-entropy loss is calculated for each batch.\n",
    "3. **Optimization:** The weights are updated using backpropagation.\n",
    "\n",
    "| Training Configuration | Value                                   |\n",
    "|-------------------------|-----------------------------------------|\n",
    "| Optimizer               | Adam                                    |\n",
    "| Learning Rate           | 0.001                                   |\n",
    "| Loss Function           | Cross-Entropy Loss                      |\n",
    "| Batch Size              | 64                                      |\n",
    "| Epochs                  | 10                                      |\n",
    "\n",
    "The trained model is saved as `simple_nn.pth`.\n",
    "\n",
    "## 5. **Model Evaluation**\n",
    "\n",
    "The model is evaluated on the test set using various metrics such as accuracy, Adjusted Rand Index (ARI), confusion matrix, and ROC AUC score.\n",
    "\n",
    "### Evaluation Steps:\n",
    "1. **Prediction:** The model predicts whether each pair of rows represents the same individual.\n",
    "2. **Metrics:** The following metrics are computed:\n",
    "   - **Accuracy:** The percentage of correct predictions.\n",
    "   - **Adjusted Rand Index (ARI):** A measure of similarity between predicted and true labels.\n",
    "   - **Confusion Matrix:** Shows the count of true positives, false positives, true negatives, and false negatives.\n",
    "   - **ROC AUC:** The area under the ROC curve, which reflects the model's ability to distinguish between positive and negative pairs.\n",
    "\n",
    "| Metric                  | Description                                  |\n",
    "|-------------------------|----------------------------------------------|\n",
    "| Accuracy                | Measures the overall correctness of predictions |\n",
    "| Adjusted Rand Index (ARI)| Measures the similarity of predicted clusters to true clusters |\n",
    "| ROC AUC                 | Measures the area under the ROC curve         |\n",
    "| Confusion Matrix        | Displays the true positive, false positive, true negative, and false negative counts |\n",
    "\n",
    "### Output:\n",
    "- **Accuracy:** The percentage of correctly classified pairs.\n",
    "- **ARI:** Agreement between the true and predicted labels.\n",
    "- **ROC AUC:** The model's ability to distinguish between positive and negative pairs.\n",
    "- **Confusion Matrix:** A summary of the classification results.\n",
    "\n",
    "### ROC Curve:\n",
    "The ROC curve is plotted to visualize the model's performance, and the curve is saved as an image file for further analysis.\n",
    "\n",
    "| Task                        | Description                                        |\n",
    "|-----------------------------|----------------------------------------------------|\n",
    "| ROC Curve                   | Visual representation of the trade-off between true positive rate and false positive rate |\n",
    "| ROC Curve Save Path          | `intermediate_results/roc_curve_NeuralNet.png`    |\n",
    "\n",
    "<!-- ![ROC Curve for Neural Network](intermediate_results/roc_curve_{model_name}.png) -->\n",
    "\n",
    "## 6. **Main Execution Workflow**\n",
    "\n",
    "### Workflow Summary:\n",
    "1. **Load Data:** Positive and negative pairs are loaded for both training and testing.\n",
    "2. **Prepare Data:** Convert the pairs into feature vectors and create labels.\n",
    "3. **Initialize Model:** A simple neural network with the appropriate input size is initialized.\n",
    "4. **Train Model:** The network is trained using cross-entropy loss over 10 epochs.\n",
    "5. **Evaluate Model:** The trained model is evaluated on the test set, and metrics are reported.\n",
    "\n",
    "### Output:\n",
    "- **Trained Model:** `simple_nn.pth`\n",
    "- **Evaluation Metrics:** Accuracy, ARI, ROC AUC, Confusion Matrix\n",
    "- **ROC Curve:** Saved as an image file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/10, Loss: 0.0816\n",
      "Epoch 2/10, Loss: 0.4050\n",
      "Epoch 3/10, Loss: 0.0105\n",
      "Epoch 4/10, Loss: 0.0107\n",
      "Epoch 5/10, Loss: 0.0107\n",
      "Epoch 6/10, Loss: 0.0108\n",
      "Epoch 7/10, Loss: 0.0108\n",
      "Epoch 8/10, Loss: 0.0108\n",
      "Epoch 9/10, Loss: 0.0108\n",
      "Epoch 10/10, Loss: 0.0108\n",
      "Model saved to models/simple_nn.pth\n",
      "Accuracy: 0.5000, ARI: 0.0000, ROC AUC: 0.5000\n",
      "Confusion Matrix:\n",
      "[[16187     0]\n",
      " [16187     0]]\n",
      "ROC curve saved for NeuralNet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score, adjusted_rand_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device selection (GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- Simple Neural Network Definition --------------------\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)  # Binary classification (0 for different, 1 for same)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# -------------------- Data Preparation --------------------\n",
    "\n",
    "def load_pairs(pairs_file):\n",
    "    \"\"\"Load pairs from a pickle file.\"\"\"\n",
    "    return pd.read_pickle(pairs_file)\n",
    "\n",
    "def prepare_data(positive_pairs, negative_pairs):\n",
    "    \"\"\"Prepare the features and labels for positive and negative pairs.\"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Positive pairs\n",
    "    for pair in positive_pairs:\n",
    "        row1 = pair[0].drop(['id', 'bi_einstaklingur']).values\n",
    "        row2 = pair[1].drop(['id', 'bi_einstaklingur']).values\n",
    "        X.append(np.concatenate([row1, row2]))\n",
    "        y.append(1)  # Label for positive pairs\n",
    "\n",
    "    # Negative pairs\n",
    "    for pair in negative_pairs:\n",
    "        row1 = pair[0].drop(['id', 'bi_einstaklingur']).values\n",
    "        row2 = pair[1].drop(['id', 'bi_einstaklingur']).values\n",
    "        X.append(np.concatenate([row1, row2]))\n",
    "        y.append(0)  # Label for negative pairs\n",
    "\n",
    "    # Convert to pandas DataFrame for ease of use\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.Series(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# -------------------- Model Training --------------------\n",
    "\n",
    "def train_model(model, X_train, y_train, n_epochs=10, batch_size=64, model_path='models/simple_nn.pth'):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)  # Move loss function to the correct device\n",
    "    \n",
    "    y_train = torch.tensor(y_train.values, dtype=torch.long).to(device)  # Ensure y_train is a torch tensor\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            batch_X = torch.tensor(X_train[i:i + batch_size], dtype=torch.float32).to(device)\n",
    "            batch_y = y_train[i:i + batch_size]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {total_loss/len(X_train):.4f}\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# -------------------- Model Evaluation --------------------\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    model.eval()\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.long).to(device)  # Convert y_test to tensor\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    ari = adjusted_rand_score(y_test, predictions)\n",
    "    confusion = confusion_matrix(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, outputs[:, 1].cpu().numpy())\n",
    "\n",
    "    # Print and save metrics\n",
    "    print(f\"Accuracy: {acc:.4f}, ARI: {ari:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "\n",
    "    # Save the ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, outputs[:, 1].cpu().numpy())\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'intermediate_results/roc_curve_{model_name}.png')\n",
    "    plt.close()\n",
    "    print(f\"ROC curve saved for {model_name}\")\n",
    "\n",
    "# -------------------- Main Execution --------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load pre-saved positive and negative pairs for train and test\n",
    "    train_positive_pairs = load_pairs('balanced_datasets/train_positive_full.pkl')\n",
    "    train_negative_pairs = load_pairs('balanced_datasets/train_negative_full.pkl')\n",
    "    test_positive_pairs = load_pairs('balanced_datasets/test_positive_full.pkl')\n",
    "    test_negative_pairs = load_pairs('balanced_datasets/test_negative_full.pkl')\n",
    "\n",
    "    # Prepare train and test data for the Simple Neural Network\n",
    "    X_train, y_train = prepare_data(train_positive_pairs, train_negative_pairs)\n",
    "    X_test, y_test = prepare_data(test_positive_pairs, test_negative_pairs)\n",
    "\n",
    "    # Convert DataFrame to numpy array\n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "\n",
    "    # Initialize and train the Simple Neural Network\n",
    "    input_size = X_train.shape[1]\n",
    "    nn_model = SimpleNN(input_size).to(device)\n",
    "    train_model(nn_model, X_train, y_train)\n",
    "\n",
    "    # Evaluate the Simple Neural Network\n",
    "    evaluate_model(nn_model, X_test, y_test, 'NeuralNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS ^"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICE-ID-YwRSIgsS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
